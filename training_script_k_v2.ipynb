{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_script_k_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RRCCq_eHOHo5Q6jf446xio533s63ouNz",
      "authorship_tag": "ABX9TyOosi/q5ts3rSPDjS+bBTk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiobarrosv/object_detection_for_grasping/blob/master/training_script_k_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJve5DYOsGJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9638bf17-e3f3-4eb5-d233-21f795c056db"
      },
      "source": [
        "!ls\n",
        "!ls drive/My\\ Drive/UFBA/Doutorado/Ssd_test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n",
            "checkpoints  checkpointsfaster_rcnn_resnet50_v1b_voc  Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIMM-dqOskzy",
        "colab_type": "text"
      },
      "source": [
        "# Instalações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS91bSiUsj5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5753058a-2763-49fc-d3f0-12ddcb3638b7"
      },
      "source": [
        "!pip install neptune-client\n",
        "!pip install mxnet-cu101\n",
        "#==1.5.0\n",
        "!pip install gluoncv\n",
        "#==0.7.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neptune-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/d6/00edcbff22f7ada15ff7b3e3c21b4cbbdd2bdd54aa72424691ad038c7d66/neptune-client-0.4.119.tar.gz (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/cc/b3c8dadc3f51fa184db10172f031c1c5206b0e67f3207217bbdd326e81a4/bravado-10.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 12.5MB/s \n",
            "\u001b[?25hCollecting py3nvml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/b3/cb30dd8cc1198ae3fdb5a320ca7986d7ca76e23d16415067eafebff8685f/py3nvml-0.2.6-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from neptune-client) (1.0.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (7.0.0)\n",
            "Collecting PyJWT\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client>=0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 12.3MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from neptune-client) (20.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client) (3.7.4.3)\n",
            "Collecting monotonic\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Collecting msgpack-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/20/6eca772d1a5830336f84aca1d8198e5a3f4715cd1c7fc36d3cc7f7185091/msgpack-python-0.5.6.tar.gz (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Collecting bravado-core>=5.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 23.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client) (2.8.1)\n",
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client) (2020.6.20)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Collecting jsonref\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (1.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Collecting webcolors; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Collecting strict-rfc3339; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n",
            "Collecting rfc3987; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: neptune-client, future, msgpack-python, strict-rfc3339\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.4.119-py2.py3-none-any.whl size=150018 sha256=b518ca8efa2480a13cd8652221aa98e9cf0a749dbd277c6818d8708967a613ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/5c/c1/a81e80761b94b4467fd3fda1fd3109463702f6247fc422eb33\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=b1998d5fc75c572e99bb26ac99ba048e87128c99136a638bc5034a584ed936e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for msgpack-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack-python: filename=msgpack_python-0.5.6-cp36-cp36m-linux_x86_64.whl size=304225 sha256=a4386283af504b49313990633c469bce7e85642cd657dbea2218cc59b096eeb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/de/86/7fa56fda12511be47ea0808f3502bc879df4e63ab168ec0406\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp36-none-any.whl size=18122 sha256=8f05798428dbac99a9b330b9846c420ad10fb6c4b0389757d61d11a7d8c06f11\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n",
            "Successfully built neptune-client future msgpack-python strict-rfc3339\n",
            "Installing collected packages: monotonic, msgpack-python, swagger-spec-validator, jsonref, simplejson, bravado-core, bravado, future, xmltodict, py3nvml, PyJWT, websocket-client, smmap, gitdb, GitPython, neptune-client, webcolors, strict-rfc3339, rfc3987\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.7 PyJWT-1.7.1 bravado-10.6.2 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.5 jsonref-0.2 monotonic-1.5 msgpack-python-0.5.6 neptune-client-0.4.119 py3nvml-0.2.6 rfc3987-1.3.8 simplejson-3.17.2 smmap-3.0.4 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 websocket-client-0.57.0 xmltodict-0.12.0\n",
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/03/02325a5de95d5cfdd43c929ea55d9cadb44d239ca3aee7e3131540c09773/mxnet_cu101-1.6.0.post0-py2.py3-none-manylinux1_x86_64.whl (711.7MB)\n",
            "\u001b[K     |████████████████████████████████| 711.7MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.6.20)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.6.0.post0\n",
            "Collecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d7/74b530c461ac3eb90f6045a645a59450de1f3d616a4926e371daa021dbd8/gluoncv-0.8.0-py2.py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gluoncv) (2.23.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gluoncv) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Installing collected packages: portalocker, gluoncv\n",
            "Successfully installed gluoncv-0.8.0 portalocker-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5L8-6kass9i",
        "colab_type": "text"
      },
      "source": [
        "# Importações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUIze8EmswyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import argparse\n",
        "\n",
        "# disable autotune\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import nd\n",
        "from mxnet import gluon\n",
        "from mxnet import autograd\n",
        "import gluoncv as gcv\n",
        "from gluoncv import data as gdata\n",
        "from gluoncv import utils as gutils\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
        "##<FASTER\n",
        "from gluoncv.data.batchify import FasterRCNNTrainBatchify, Append # ,Tuple \n",
        "from gluoncv.data.transforms.presets.rcnn import FasterRCNNDefaultTrainTransform, \\\n",
        "    FasterRCNNDefaultValTransform\n",
        "from gluoncv.utils.parallel import Parallel\n",
        "from gluoncv.utils.metrics.rcnn import RPNAccMetric, RPNL1LossMetric, RCNNAccMetric, \\\n",
        "    RCNNL1LossMetric\n",
        "from gluoncv.model_zoo.rcnn.faster_rcnn.data_parallel import ForwardBackwardTask\n",
        "##/>\n",
        "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultTrainTransform\n",
        "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultValTransform\n",
        "from gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform\n",
        "from gluoncv.data.transforms.presets.ssd import SSDDefaultValTransform\n",
        "from gluoncv.utils.metrics.voc_detection import VOC07MApMetric\n",
        "from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
        "import gluoncv.data.transforms.bbox as tbbox\n",
        "import gluoncv.data.transforms.image as timage\n",
        "import gluoncv.data.transforms.experimental as experimental\n",
        "import cv2\n",
        "from gluoncv.utils.bbox import bbox_iou \n",
        "# from mxnet.contrib import amp\n",
        "\n",
        "import neptune\n",
        "os.environ['MXNET_CUDNN_AUTOTUNE_DEFAULT'] = '0'\n",
        "os.environ['NEPTUNE_API_TOKEN'] = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiM2UxMWNkZTgtODZhZi00MWFmLWE3ZDEtOWYwZTliMzk4ZDFmIn0='\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q7rrf6Ws4kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SSDCustomValTransform(object):\n",
        "    \"\"\"Default SSD training transform which includes tons of image augmentations.\"\"\"\n",
        "\n",
        "    def __init__(self, width, height, anchors=None, mean=(0.485, 0.456, 0.406),\n",
        "                 std=(0.229, 0.224, 0.225), iou_thresh=0.5, box_norm=(0.1, 0.1, 0.2, 0.2),\n",
        "                 **kwargs):\n",
        "        self._width = width\n",
        "        self._height = height\n",
        "        self._anchors = anchors\n",
        "        self._mean = mean\n",
        "        self._std = std\n",
        "        if anchors is None:\n",
        "            return\n",
        "\n",
        "        # since we do not have predictions yet, so we ignore sampling here\n",
        "        from gluoncv.model_zoo.ssd.target import SSDTargetGenerator\n",
        "        self._target_generator = SSDTargetGenerator(\n",
        "            iou_thresh=iou_thresh, stds=box_norm, negative_mining_ratio=-1, **kwargs)\n",
        "\n",
        "    def __call__(self, src, label):\n",
        "        \"\"\"Apply transform to validation image/label.\"\"\"\n",
        "        # resize with random interpolation\n",
        "        h, w, _ = src.shape\n",
        "        img = timage.imresize(src, self._width, self._height, interp=9)\n",
        "        bbox = tbbox.resize(label, (w, h), (self._width, self._height))\n",
        "\n",
        "        # to tensor\n",
        "        img = mx.nd.image.to_tensor(img)\n",
        "        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)\n",
        "\n",
        "        if self._anchors is None:\n",
        "            return img, bbox.astype(img.dtype)\n",
        "\n",
        "        # generate training target so cpu workers can help reduce the workload on gpu\n",
        "        gt_bboxes = mx.nd.array(bbox[np.newaxis, :, :4])\n",
        "        gt_ids = mx.nd.array(bbox[np.newaxis, :, 4:5])\n",
        "        cls_targets, box_targets, _ = self._target_generator(\n",
        "            self._anchors, None, gt_bboxes, gt_ids)\n",
        "        return img, cls_targets[0], box_targets[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e5ZnCJLuHR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwJCO-Zs7Hf",
        "colab_type": "text"
      },
      "source": [
        "# SSD and YOLO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni4J65SatJl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class training_network():\n",
        "    def __init__(self, model='ssd300', ctx='gpu', resume_training=False, batch_size=4, num_workers=2, lr=0.001, \n",
        "                 lr_decay=0.1, lr_decay_epoch='60, 80', wd=0.0005, momentum=0.9, start_epoch=0,\n",
        "                 epochs=2, dataset='voc', network='vgg16_atrous', resume='',\n",
        "                 beta1=0.9, beta2=0.999, epsilon=1e-08, validation_threshold=0.5, nms_threshold=0.5, optimizer='sgd', x_id=None):\n",
        "        \n",
        "        # exp=False\n",
        "        \"\"\"\n",
        "        Script responsible for training the class\n",
        "\n",
        "        Arguments:\n",
        "            val_interval (int, default: 1): Epoch interval for validation, increase the number will reduce the\n",
        "                training time if validation is slow.\n",
        "            wd (float, default: 0.0005): Weight decay, default is 5e-4\n",
        "            momentum (float, default:0.9): SGD momentum, default is 0.9\n",
        "            lr_decay_epoch (str, default: '60, 80'): epoches at which learning rate decays. default is 60, 80.\n",
        "            lr_decay (float, default: 0.1): decay rate of learning rate. default is 0.1.\n",
        "            lr (float, default: 0.001): Learning rate, default is 0.001\n",
        "            start_epoch (int, default: 0): Starting epoch for resuming, default is 0 for new training. You can\n",
        "                specify it to 100 for example to start from 100 epoch.\n",
        "            resume (str, default: ''): Resume from previously saved parameters if not None. For example, you \n",
        "                can resume from ./ssd_xxx_0123.params'\n",
        "            epochs (int, default:2): Training epochs.\n",
        "            num_worker (int, default: 2): number to accelerate data loading\n",
        "            dataset (str, default:'voc'): Training dataset. Now support voc.\n",
        "            batch_size (int, default: 4): Training mini-batch size\n",
        "            data_shape (int, default: 300): Input data shape, use 300, 512.\n",
        "            network (str, default:'vgg16_atrous'): Base network name which serves as feature extraction base.\n",
        "        \"\"\"\n",
        "\n",
        "        # amp.init()\n",
        "\n",
        "        # TRAINING PARAMETERS\n",
        "        self.net_type='SSD_or_YOLO'\n",
        "        self.x_id = x_id\n",
        "        self.old_save = None\n",
        "        self.resume_training = resume_training\n",
        "        self.batch_size=batch_size\n",
        "        self.num_workers=num_workers\n",
        "        self.learning_rate = lr\n",
        "        self.weight_decay = wd\n",
        "        self.momentum = momentum\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_decay = lr_decay\n",
        "        self.lr_decay_epoch = lr_decay_epoch\n",
        "        self.start_epoch = start_epoch\n",
        "        self.epochs = epochs\n",
        "        self.resume = resume\n",
        "        self.validation_threshold = validation_threshold\n",
        "        self.nms_threshold = nms_threshold\n",
        "        # self.experiment = experiment\n",
        "        self.beta1=beta1\n",
        "        self.beta2=beta2\n",
        "        self.epsilon=epsilon\n",
        "        self.best_map = 0\n",
        "\n",
        "        if ctx == 'cpu':\n",
        "            self.ctx = [mx.cpu()]\n",
        "        elif ctx == 'gpu':\n",
        "            self.ctx = [mx.gpu(0)]\n",
        "        else:\n",
        "            raise ValueError('Invalid context.')\n",
        "            \n",
        "        # fix seed for mxnet, numpy and python builtin random generator.\n",
        "        gutils.random.seed(233)\n",
        "\n",
        "        if model.lower() == 'ssd_300_vgg16_atrous_voc':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 300, 300\n",
        "        elif model.lower() == 'ssd_512_resnet50_v1_voc':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 512, 512\n",
        "        elif model.lower() == 'ssd_512_vgg16_atrous_voc':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 512, 512\n",
        "        elif model.lower() == 'ssd_300_vgg16_atrous_coco':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 300, 300\n",
        "        elif model.lower() == 'ssd_512_vgg16_atrous_coco':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 512, 512\n",
        "        elif model.lower() == 'ssd_512_resnet50_v1_coco':\n",
        "            self.network = 'ssd'\n",
        "            self.width, self.height = 512, 512\n",
        "        elif model.lower() == 'yolo3_darknet53_voc':\n",
        "            self.network = 'yolo'\n",
        "            self.width, self.height = 320, 320\n",
        "        elif model.lower() == 'yolo3_darknet53_coco':\n",
        "            self.network = 'yolo'\n",
        "            self.width, self.height = 320, 320\n",
        "        else:\n",
        "            raise ValueError('Invalid model `{}`.'.format(model.lower()))\n",
        "                \n",
        "        # TODO: Specify the checkpoints save path\n",
        "        self.save_prefix = 'drive/My Drive/UFBA/Doutorado/Ssd_test/checkpoints/checkp'\n",
        "        \n",
        "        # train and val rec file\n",
        "        self.train_file = 'drive/My Drive/UFBA/Doutorado/Ssd_test/Dataset/train_teste_7_300_300.rec'\n",
        "        self.val_file = 'drive/My Drive/UFBA/Doutorado/Ssd_test/Dataset/val_teste_7_300_300.rec'\n",
        "\n",
        "        self.classes = ['bar_clamp', 'gear_box', 'vase', 'part_1', 'part_3', 'nozzle', 'pawn', 'turbine_housing'] # please, follow the order of the config.json file\n",
        "        print('Classes: ', self.classes)\n",
        "\n",
        "        # pretrained or pretrained_base?\n",
        "        # pretrained (bool or str) – Boolean value controls whether to load the default \n",
        "        # pretrained weights for model. String value represents the hashtag for a certain \n",
        "        # version of pretrained weights.\n",
        "        # pretrained_base (bool or str, optional, default is True) – Load pretrained base \n",
        "        # network, the extra layers are randomized. Note that if pretrained is True, this\n",
        "        # has no effect.\n",
        "        self.net = get_model(model, pretrained=True, norm_layer=gluon.nn.BatchNorm)\n",
        "        self.net.reset_class(self.classes)\n",
        "        \n",
        "        # Initialize the weights\n",
        "        if self.resume_training:\n",
        "            self.net.initialize(force_reinit=True, ctx=self.ctx)\n",
        "            self.net.load_params(self.resume, ctx=self.ctx)\n",
        "        else:\n",
        "            for param in self.net.collect_params().values():\n",
        "                if param._data is not None:\n",
        "                    continue\n",
        "                param.initialize()\n",
        "        print('aqui')\n",
        "\n",
        "    def get_dataset(self):\n",
        "        validation_threshold = self.validation_threshold\n",
        "        self.train_dataset = gdata.RecordFileDetection(self.train_file)\n",
        "        self.val_dataset = gdata.RecordFileDetection(self.val_file)\n",
        "        # we are only using VOCMetric for evaluation\n",
        "        if not self.net_type =='faster':\n",
        "          self.val_metric = VOC07MApMetric(iou_thresh=validation_threshold, class_names=self.net.classes)\n",
        "        else: \n",
        "          self.val_metric = VOC07MApMetric(iou_thresh=validation_threshold, class_names=self.classes)\n",
        "\n",
        "\n",
        "    def show_summary(self):\n",
        "        self.net.summary(mx.nd.ones((1, 3, self.height, self.width)))\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        width, height = self.width, self.height\n",
        "        train_dataset = self.train_dataset\n",
        "        val_dataset = self.val_dataset\n",
        "        batch_size = self.batch_size\n",
        "        num_workers = self.num_workers\n",
        "        network = self.network\n",
        "        print('aqui 0')\n",
        "        if network == 'ssd':\n",
        "            # use fake data to generate fixed anchors for target generation\n",
        "            with autograd.train_mode():\n",
        "                _, _, anchors = self.net(mx.nd.zeros((1, 3, height, width)))\n",
        "\n",
        "            batchify_fn = Tuple(Stack(), Stack(), Stack())  # stack image, cls_targets, box_targets\n",
        "            train_loader = gluon.data.DataLoader(train_dataset.transform(SSDDefaultTrainTransform(width, height, anchors)),\n",
        "                                                 batch_size, True, \n",
        "                                                 batchify_fn=batchify_fn, \n",
        "                                                 last_batch='rollover', \n",
        "                                                 num_workers=num_workers)\n",
        "\n",
        "            # Val verdadeiro\n",
        "            val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
        "            val_loader = gluon.data.DataLoader(val_dataset.transform(SSDDefaultValTransform(width, height)),\n",
        "                                               batch_size, False, \n",
        "                                               batchify_fn=val_batchify_fn, \n",
        "                                               last_batch='keep', \n",
        "                                               num_workers=num_workers)\n",
        "          \n",
        "            # use fake data to generate fixed anchors for target generation\n",
        "            with mx.Context(mx.gpu(0)):\n",
        "                anchors2 = anchors\n",
        "\n",
        "            val_loader_loss = gluon.data.DataLoader(val_dataset.transform(SSDCustomValTransform(width, height, anchors2)),\n",
        "                                                    batch_size, True, \n",
        "                                                    batchify_fn=batchify_fn, \n",
        "                                                    last_batch='rollover', \n",
        "                                                    num_workers=num_workers)\n",
        "            self.val_loader_loss = val_loader_loss\n",
        "        elif network == 'yolo':\n",
        "            print('aqui 1')\n",
        "            batchify_fn = Tuple(*([Stack() for _ in range(6)] + [Pad(axis=0, pad_val=-1) for _ in range(1)]))  # stack image, all targets generated\n",
        "            # if args.no_random_shape:\n",
        "            train_loader = gluon.data.DataLoader(train_dataset.transform(YOLO3DefaultTrainTransform(width, height, self.net)),\n",
        "                                                 batch_size, True, \n",
        "                                                 batchify_fn=batchify_fn, \n",
        "                                                 last_batch='rollover', \n",
        "                                                 num_workers=num_workers)\n",
        "\n",
        "            val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
        "            val_loader = gluon.data.DataLoader(val_dataset.transform(YOLO3DefaultValTransform(width, height)),\n",
        "                                               batch_size, False, \n",
        "                                               batchify_fn=val_batchify_fn, \n",
        "                                               last_batch='keep', \n",
        "                                               num_workers=num_workers)\n",
        "            print('aqui 2')\n",
        "        else:\n",
        "            raise ValueError(\"Network {} not implemented\".format(network))\n",
        "\n",
        "        self.val_loader = val_loader\n",
        "        self.train_loader = train_loader\n",
        "\n",
        "    # def save_params(self, current_map, epoch):\n",
        "    #     prefix = self.save_prefix\n",
        "    #     best_map = self.best_map\n",
        "\n",
        "    #     pre = self.save_prefix,\n",
        "    #     print(pre) \n",
        "\n",
        "    #     current_map = float(current_map)        \n",
        "    #     if current_map > best_map:\n",
        "    #         best_map = current_map\n",
        "    #         self.net.save_parameters('/{:s}_best_epoch_{:04d}_map_{:.4f}.params'.format(prefix, epoch, current_map))\n",
        "        \n",
        "    #     self.best_map = best_map\n",
        "    #     print('Best map: ', self.best_map)\n",
        "\n",
        "\n",
        "    def save_params(self, current_map, epoch):\n",
        "        prefix = self.save_prefix #self.save_prefix\n",
        "        pre = '{:s}/{:s}/{:s}/'.format(prefix, self.net_type, self.x_id)\n",
        "        print(prefix)\n",
        "        best_map = self.best_map\n",
        "\n",
        "        if not os.path.exists(pre):\n",
        "          os.makedirs(pre)\n",
        "\n",
        "        current_map = float(current_map)        \n",
        "        if current_map > best_map:\n",
        "            best_map = current_map\n",
        "            cur_save= '{:s}_BE_{:04d}_map_{:.4f}.params'.format(pre, epoch, current_map) \n",
        "            print(cur_save)\n",
        "            self.net.save_parameters(cur_save)\n",
        "            if not (self.old_save == None):\n",
        "              open(self.old_save, 'w').close() #overwrite and make the file blank instead - ref: https://stackoverflow.com/a/4914288/3553367\n",
        "              os.remove(self.old_save) #delete the blank file from google drive will move the file to bin instead\n",
        "            self.old_save = (cur_save)\n",
        "        \n",
        "        self.best_map = best_map\n",
        "        print('Best map: ', self.best_map)\n",
        "\n",
        "    def val_loss(self):\n",
        "        \"\"\"Training pipeline\"\"\"        \n",
        "        val_data = self.val_loader_loss\n",
        "        ctx = self.ctx\n",
        "        val_metric = self.val_metric\n",
        "\n",
        "        mbox_loss = gcv.loss.SSDMultiBoxLoss()\n",
        "        ce_metric = mx.metric.Loss('CrossEntropy')\n",
        "        smoothl1_metric = mx.metric.Loss('SmoothL1')\n",
        "\n",
        "        ce_metric.reset() # Resets the internal evaluation result to initial state.\n",
        "        smoothl1_metric.reset() # Resets the internal evaluation result to initial state.\n",
        "\n",
        "        for i, batch in enumerate(val_data):\n",
        "            batch_size = batch[0].shape[0]\n",
        "            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "            cls_targets = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "            box_targets = gluon.utils.split_and_load(batch[2], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "            cls_preds = []\n",
        "            box_preds = []\n",
        "            for x in data:\n",
        "                cls_pred, box_pred, _ = self.net(x)\n",
        "                cls_preds.append(cls_pred)\n",
        "                box_preds.append(box_pred)\n",
        "                # descobrir o id de cada ifnerência pra usar no iou\n",
        "            \n",
        "            sum_loss, cls_loss, box_loss = mbox_loss(\n",
        "                cls_preds, box_preds, cls_targets, box_targets)\n",
        "        \n",
        "        ce_metric.update(0, [l * batch_size for l in cls_loss])\n",
        "        smoothl1_metric.update(0, [l * batch_size for l in box_loss])\n",
        "\n",
        "        name1, loss1 = ce_metric.get()\n",
        "        name2, loss2 = smoothl1_metric.get()\n",
        "\n",
        "        return name1, loss1, name2, loss2\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Test on validation dataset.\"\"\"\n",
        "        val_data = self.val_loader\n",
        "        ctx = self.ctx\n",
        "        val_metric = self.val_metric\n",
        "        nms_threshold = self.nms_threshold\n",
        "        validation_threshold = self.validation_threshold\n",
        "\n",
        "        val_metric.reset()\n",
        "        # set nms threshold and topk constraint\n",
        "        # post_nms = maximum number of objects per image\n",
        "        self.net.set_nms(nms_thresh=nms_threshold, nms_topk=200, post_nms=len(self.classes)) # default: iou=0.45 e topk=400\n",
        "\n",
        "        # >>>> Verificar eficácia\n",
        "        # mx.nd.waitall()\n",
        "\n",
        "        # allow the MXNet engine to perform graph optimization for best performance.\n",
        "        self.net.hybridize(static_alloc=True, static_shape=True)\n",
        "\n",
        "        num_of_classes = len(self.classes)\n",
        "        # total number of correct prediction by class\n",
        "        tp = [0] * num_of_classes\n",
        "        # false positives by class\n",
        "        fp = [0] * num_of_classes\n",
        "        # count the number of gt by class\n",
        "        gt_by_class = [0] * num_of_classes\n",
        "        # rec and prec by class\n",
        "        rec_by_class = [0] * num_of_classes\n",
        "        prec_by_class = [0] * num_of_classes\n",
        "        confusion_matrix = np.zeros((num_of_classes, num_of_classes))\n",
        "\n",
        "        for batch in val_data:\n",
        "            batch_size = batch[0].shape[0]\n",
        "            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "            label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
        "\n",
        "            pred_bboxes_list = []\n",
        "            pred_label_list = []\n",
        "            pred_scores_list = []\n",
        "            gt_bboxes_list = []\n",
        "            gt_label_list = []\n",
        "            \n",
        "            for x, y in zip(data, label):\n",
        "                # get prediction results\n",
        "                ids, scores, bboxes = self.net(x)\n",
        "                pred_label_list.append(ids)\n",
        "                pred_scores_list.append(scores)\n",
        "                # clip to image size\n",
        "                pred_bboxes_list.append(bboxes.clip(0, batch[0].shape[2]))\n",
        "                # split ground truths\n",
        "                gt_label_list.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
        "                gt_bboxes_list.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
        "\n",
        "            # Uncomment the following line if you want to plot the images in each inference to visually  check the tp, fp and fn \n",
        "            # self.show_images(x, pred_label_list, pred_bboxes_list, gt_label_list, gt_bboxes_list)\n",
        "            \n",
        "            # update metric\n",
        "            val_metric.update(pred_bboxes_list, pred_label_list, pred_scores_list, gt_bboxes_list, gt_label_list) #, gt_difficults)\n",
        "            \n",
        "            # Get Micro Averaging (precision and recall by each class) in each batch\n",
        "            for img in range(batch_size):\n",
        "                # count +1 for this class id. It will get the total number of gt by class\n",
        "                # It is useful when considering unbalanced datasets\n",
        "                for gt_idx in gt_label_list[0][img]:\n",
        "                    index = int(gt_idx.asnumpy()[0])\n",
        "                    gt_by_class[index] += 1\n",
        "            \n",
        "                for (pred_label, pred_bbox) in zip(pred_label_list[0][img], list(pred_bboxes_list[0][img])):\n",
        "                    pred_label = int(pred_label.asnumpy()[0])\n",
        "                    pred_bbox = pred_bbox.asnumpy()\n",
        "                    pred_bbox = np.expand_dims(pred_bbox, axis=0)\n",
        "                    match = 0\n",
        "                    for (gt_bbox_label, gt_bbox_coordinates) in zip(gt_label_list[0][img], list(gt_bboxes_list[0][img])):\n",
        "                        gt_bbox_coord = gt_bbox_coordinates.asnumpy()\n",
        "                        gt_bbox_coord = np.expand_dims(gt_bbox_coord, axis=0)\n",
        "                        gt_bbox_label = int(gt_bbox_label.asnumpy()[0])\n",
        "                        iou = bbox_iou(pred_bbox, gt_bbox_coord)\n",
        "                        \n",
        "                        # Correct inference\n",
        "                        if iou > validation_threshold and pred_label == gt_bbox_label:\n",
        "                            confusion_matrix[gt_bbox_label][pred_label] += 1\n",
        "                            tp[gt_bbox_label] += 1 # Correct classification\n",
        "                            match = 1\n",
        "                        # Incorrect inference - missed the correct class but put the bounding box in other class\n",
        "                        elif iou > validation_threshold:\n",
        "                            confusion_matrix[gt_bbox_label][pred_label] += 1\n",
        "                            fp[pred_label] += 1\n",
        "                            match = 1\n",
        "                        \n",
        "                    if not match:\n",
        "                        fp[pred_label] += 1\n",
        "                                \n",
        "        # calculate the Recall and Precision by class\n",
        "        tp = np.array(tp) # we can also sum the matrix diagonal\n",
        "        fp = np.array(fp)\n",
        "        \n",
        "        fp_sum = sum(fp)\n",
        "        tp_sum = sum(tp)\n",
        "\n",
        "        # rec and prec according to the micro averaging\n",
        "        for i, (gt_value, tp_value) in enumerate(zip(gt_by_class, tp)):\n",
        "            rec_by_class[i] += tp_value/gt_value\n",
        "            # If an element of fp + tp is 0,\n",
        "            # the corresponding element of prec[l] is nan.\n",
        "            with np.errstate(divide='ignore', invalid='ignore'):\n",
        "                prec_by_class[i] += tp_value/(tp_value+fp[i])\n",
        "\n",
        "        return val_metric.get(), rec_by_class, prec_by_class\n",
        "\n",
        "    def create_optimizer(self):\n",
        "        optimizer = self.optimizer\n",
        "        momentum = self.momentum\n",
        "        wd = self.weight_decay\n",
        "        lr = self.learning_rate\n",
        "        beta1 = self.beta1\n",
        "        beta2 = self.beta2\n",
        "        epsilon = self.epsilon\n",
        "        \n",
        "        if optimizer.lower() == 'sgd':\n",
        "            # wd: The weight decay (or L2 regularization) coefficient.\n",
        "            self.trainer = gluon.Trainer(self.net.collect_params(), optimizer,\n",
        "                                    {'learning_rate': lr, 'wd': wd, 'momentum': momentum})\n",
        "        elif optimizer.lower() == 'adam':\n",
        "            self.trainer = gluon.Trainer(self.net.collect_params(), optimizer,\n",
        "                                    {'learning_rate': lr, 'beta1': beta1, 'beta2': beta2, \n",
        "                                     'epsilon': epsilon})\n",
        "\n",
        "    def validate_main(self, epoch):\n",
        "        # consider reduce the frequency of validation to save time\n",
        "        (map_name, mean_ap), rec_by_class, prec_by_class = self.validate()\n",
        "        val_msg = '\\n'.join(['{}={}'.format(k, v) for k, v in zip(map_name, mean_ap)])\n",
        "        \n",
        "        for i, class_name in enumerate(self.classes):\n",
        "            experiment.log_metric('rec_by_class_val_' + class_name, epoch, rec_by_class[i])\n",
        "            experiment.log_metric('prec_by_class_val_' + class_name, epoch, prec_by_class[i])\n",
        "        \n",
        "        for k, v in zip(map_name, mean_ap):\n",
        "            experiment.log_metric('map_' + k, epoch, v)\n",
        "        \n",
        "        print('[Epoch {}] Validation: \\n{}'.format(epoch, val_msg))\n",
        "        current_map = float(mean_ap[-1])\n",
        "        \n",
        "        self.save_params(current_map, epoch)    \n",
        "\n",
        "    def ssd_train(self):\n",
        "        \"\"\"Training pipeline\"\"\"\n",
        "        ctx = self.ctx\n",
        "        train_data = self.train_loader\n",
        "        start_epoch = self.start_epoch\n",
        "        epochs = self.epochs\n",
        "        # experiment = self.experiment\n",
        "        trainer = self.trainer\n",
        "        optimizer = self.optimizer\n",
        "\n",
        "        mbox_loss = gcv.loss.SSDMultiBoxLoss()\n",
        "        ce_metric = mx.metric.Loss('CrossEntropy')\n",
        "        smoothl1_metric = mx.metric.Loss('SmoothL1')\n",
        "\n",
        "        if optimizer =='sgd':\n",
        "            # lr decay policy\n",
        "            lr_decay = float(lr_decay)\n",
        "            lr_steps = sorted([float(ls) for ls in lr_decay_epoch.split(',') if ls.strip()]) \n",
        "\n",
        "        print('Start training from [Epoch {}]'.format(start_epoch))\n",
        "        start_train_time = time.time()\n",
        "        for epoch in range(start_epoch, epochs):\n",
        "            start_epoch_time = time.time()\n",
        "            experiment.log_metric('learning_rate', epoch, trainer.learning_rate)\n",
        "\n",
        "            if optimizer == 'sgd':\n",
        "              while lr_steps and epoch >= lr_steps[0]:\n",
        "                  new_lr = trainer.learning_rate * lr_decay\n",
        "                  lr_steps.pop(0) # removes the first element in the list\n",
        "                  trainer.set_learning_rate(new_lr) # Set a new learning rate\n",
        "                  print(\"[Epoch {}] Set learning rate to {}\".format(epoch, new_lr))\n",
        "                \n",
        "            ce_metric.reset() # Resets the internal evaluation result to initial state.\n",
        "            smoothl1_metric.reset() # Resets the internal evaluation result to initial state.\n",
        "\n",
        "            tic = time.time() # each epoch time in seconds\n",
        "            btic = time.time() # each batch time interval in seconds\n",
        "                \n",
        "            # Activates or deactivates HybridBlocks recursively. it speeds up the training process\n",
        "            self.net.hybridize(static_alloc=True, static_shape=True)\n",
        "                \n",
        "            for i, batch in enumerate(train_data):\n",
        "                # Wait for completion of previous iteration to\n",
        "                # avoid unnecessary memory allocation\n",
        "                # nd.waitall()\n",
        "\n",
        "                batch_size = batch[0].shape[0]\n",
        "                data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "                cls_targets = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "                box_targets = gluon.utils.split_and_load(batch[2], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "                with autograd.record():\n",
        "                    cls_preds = []\n",
        "                    box_preds = []\n",
        "                    for x in data:\n",
        "                        cls_pred, box_pred, _ = self.net(x)\n",
        "                        cls_preds.append(cls_pred)\n",
        "                        box_preds.append(box_pred)\n",
        "                        \n",
        "                    sum_loss, cls_loss, box_loss = mbox_loss(\n",
        "                        cls_preds, box_preds, cls_targets, box_targets)\n",
        "                        \n",
        "                    # with amp.scale_loss(sum_loss, trainer) as scaled_loss:\n",
        "                        # autograd.backward(scaled_loss)\n",
        "                    autograd.backward(sum_loss)\n",
        "                    \n",
        "                # since we have already normalized the loss, we don't want to normalize\n",
        "                # by batch-size anymore\n",
        "                trainer.step(1)\n",
        "                ce_metric.update(0, [l * batch_size for l in cls_loss])\n",
        "                smoothl1_metric.update(0, [l * batch_size for l in box_loss])\n",
        "\n",
        "                name1, loss1 = ce_metric.get()\n",
        "                name2, loss2 = smoothl1_metric.get()\n",
        "                print('[Epoch {}][Batch {}], Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}'.format(\n",
        "                    epoch, i, batch_size/(time.time()-btic), name1, loss1, name2, loss2))\n",
        "                btic = time.time()\n",
        "\n",
        "            # log the epoch info\n",
        "            name1, loss1 = ce_metric.get()\n",
        "            name2, loss2 = smoothl1_metric.get()\n",
        "            experiment.log_metric('cross_entropy_training_loss', epoch, loss1)\n",
        "            experiment.log_metric('smooth_l1_training_loss', epoch, loss2) \n",
        "            experiment.log_metric('train_sum_loss', epoch, loss1 + loss2) \n",
        "\n",
        "            print('[Epoch {}] - Time (min): {:.3f}, {}={:.3f}, {}={:.3f}'.format(\n",
        "                epoch, (time.time()-tic)/60, name1, loss1, name2, loss2))\n",
        "\n",
        "            # log SSD LOSS            \n",
        "            val_name1, val_loss1, val_name2, val_loss2 = self.val_loss()\n",
        "            current_val_loss = val_loss1 + val_loss2\n",
        "            experiment.log_metric('cross_entropy_validation_loss', epoch, val_loss1)\n",
        "            experiment.log_metric('smooth_l1_validation_loss', epoch, val_loss2) \n",
        "            experiment.log_metric('validation_sum_loss', epoch, current_val_loss) \n",
        "\n",
        "            self.validate_main(epoch)\n",
        "        \n",
        "        # Displays the total time of the training\n",
        "        print('Train time {:.3f}'.format(time.time() - start_train_time))\n",
        "    \n",
        "    def yolo_train(self):\n",
        "        \"\"\"Training pipeline\"\"\"\n",
        "        ctx = self.ctx\n",
        "        train_data = self.train_loader\n",
        "        start_epoch = self.start_epoch\n",
        "        epochs = self.epochs\n",
        "        # experiment = self.experiment\n",
        "        trainer = self.trainer\n",
        "        optimizer = self.optimizer\n",
        "\n",
        "        # metrics\n",
        "        obj_metrics = mx.metric.Loss('ObjLoss')\n",
        "        center_metrics = mx.metric.Loss('BoxCenterLoss')\n",
        "        scale_metrics = mx.metric.Loss('BoxScaleLoss')\n",
        "        cls_metrics = mx.metric.Loss('ClassLoss')\n",
        "\n",
        "        if optimizer =='sgd':\n",
        "            # lr decay policy\n",
        "            lr_decay = float(lr_decay)\n",
        "            lr_steps = sorted([float(ls) for ls in lr_decay_epoch.split(',') if ls.strip()]) \n",
        "\n",
        "        print('Start training from [Epoch {}]'.format(start_epoch))\n",
        "        start_train_time = time.time()\n",
        "        for epoch in range(start_epoch, epochs):\n",
        "            experiment.log_metric('learning_rate', epoch, trainer.learning_rate)\n",
        "\n",
        "            start_epoch_time = time.time()\n",
        "            tic = time.time() # each epoch time in seconds\n",
        "            btic = time.time() # each batch time interval in seconds\n",
        "            mx.nd.waitall()\n",
        "            self.net.hybridize()\n",
        "            for i, batch in enumerate(train_data):\n",
        "                data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "                # objectness, center_targets, scale_targets, weights, class_targets\n",
        "                fixed_targets = [gluon.utils.split_and_load(batch[it], ctx_list=ctx, batch_axis=0) for it in range(1, 6)]\n",
        "                gt_boxes = gluon.utils.split_and_load(batch[6], ctx_list=ctx, batch_axis=0)\n",
        "                sum_loss = []\n",
        "                obj_losses = []\n",
        "                center_losses = []\n",
        "                scale_losses = []\n",
        "                cls_losses = []\n",
        "                with autograd.record():\n",
        "                    for ix, x in enumerate(data):\n",
        "                        obj_loss, center_loss, scale_loss, cls_loss = self.net(x, gt_boxes[ix], *[ft[ix] for ft in fixed_targets])\n",
        "                        sum_loss.append(obj_loss + center_loss + scale_loss + cls_loss)\n",
        "                        obj_losses.append(obj_loss)\n",
        "                        center_losses.append(center_loss)\n",
        "                        scale_losses.append(scale_loss)\n",
        "                        cls_losses.append(cls_loss)\n",
        "                    # if args.amp:\n",
        "                    # with amp.scale_loss(sum_loss, trainer) as scaled_loss:\n",
        "                    #         autograd.backward(scaled_loss)\n",
        "                    # else:\n",
        "                    autograd.backward(sum_loss)\n",
        "                trainer.step(self.batch_size)\n",
        "                obj_metrics.update(0, obj_losses)\n",
        "                center_metrics.update(0, center_losses)\n",
        "                scale_metrics.update(0, scale_losses)\n",
        "                cls_metrics.update(0, cls_losses)\n",
        "                # if self.log_interval and not (i + 1) % self.log_interval:\n",
        "                name1, loss1 = obj_metrics.get()\n",
        "                name2, loss2 = center_metrics.get()\n",
        "                name3, loss3 = scale_metrics.get()\n",
        "                name4, loss4 = cls_metrics.get()\n",
        "                print('[Epoch {}][Batch {}], LR: {:.2E}, Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}'.format(\n",
        "                    epoch, i, trainer.learning_rate, self.batch_size/(time.time()-btic), name1, loss1, name2, loss2, name3, loss3, name4, loss4))\n",
        "                btic = time.time()\n",
        "\n",
        "\n",
        "            name1, loss1 = obj_metrics.get()\n",
        "            name2, loss2 = center_metrics.get()\n",
        "            name3, loss3 = scale_metrics.get()\n",
        "            name4, loss4 = cls_metrics.get()\n",
        "            experiment.log_metric('Obj_metrics', epoch, loss1)\n",
        "            experiment.log_metric('Center_metrics', epoch, loss2)\n",
        "            experiment.log_metric('Scale_metrics', epoch, loss3)\n",
        "            experiment.log_metric('cls_metrics', epoch, loss4)\n",
        "            print('[Epoch {}] Training cost: {:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}'.format(\n",
        "                epoch, (time.time()-tic), name1, loss1, name2, loss2, name3, loss3, name4, loss4))\n",
        "\n",
        "            self.validate_main(epoch)\n",
        "        \n",
        "        # Displays the total time of the training\n",
        "        print('Train time {:.3f}'.format(time.time() - start_train_time))\n",
        "\n",
        "    def faster_train(self):\n",
        "        print(\"Train start\")\n",
        "        \"\"\"Training pipeline\"\"\"\n",
        "        self.kv_store = 'device' if (False and 'nccl' in self.kv_store) else self.kv_store #if (self.amp and 'nccl' in self.kv_store) else self.kv_store\n",
        "        kv = mx.kvstore.create(self.kv_store)\n",
        "        self.net.collect_params().setattr('grad_req', 'null')\n",
        "        self.net.collect_train_params().setattr('grad_req', 'write')\n",
        "        optimizer_params = {'learning_rate': self.lr, 'wd': self.wd, 'momentum': self.momentum}\n",
        "        self.create_optimizer(kv)\n",
        "        trainer = self.trainer\n",
        "        lr_decay = float(self.lr_decay)\n",
        "        lr_steps = sorted([float(ls) for ls in self.lr_decay_epoch.split(',') if ls.strip()])\n",
        "        lr_warmup = float(self.lr_warmup)  # avoid int division\n",
        "\n",
        "        # TODO(zhreshold) losses?\n",
        "        rpn_cls_loss = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
        "        rpn_box_loss = mx.gluon.loss.HuberLoss(rho=self.rpn_smoothl1_rho)  # == smoothl1\n",
        "        rcnn_cls_loss = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "        rcnn_box_loss = mx.gluon.loss.HuberLoss(rho=self.rcnn_smoothl1_rho)  # == smoothl1\n",
        "        metrics = [mx.metric.Loss('RPN_Conf'),\n",
        "                   mx.metric.Loss('RPN_SmoothL1'),\n",
        "                   mx.metric.Loss('RCNN_CrossEntropy'),\n",
        "                   mx.metric.Loss('RCNN_SmoothL1'), ]\n",
        "\n",
        "        rpn_acc_metric = RPNAccMetric()\n",
        "        rpn_bbox_metric = RPNL1LossMetric()\n",
        "        rcnn_acc_metric = RCNNAccMetric()\n",
        "        rcnn_bbox_metric = RCNNL1LossMetric()\n",
        "        metrics2 = [rpn_acc_metric, rpn_bbox_metric, rcnn_acc_metric, rcnn_bbox_metric]\n",
        "\n",
        "        if self.custom_model:\n",
        "            print('Custom model enabled. Expert Only!! Currently non-FPN model is not supported!!'\n",
        "                        ' Default setting is for MS-COCO.')#logger.info\n",
        "        #logger.info(args)\n",
        "\n",
        "        print('Start training from [Epoch {}]'.format(self.start_epoch))#logger.info\n",
        "        best_map = [0]\n",
        "        for epoch in range(self.start_epoch, self.epochs):\n",
        "\n",
        "            #self.experiment.log_metric('learning_rate', epoch, trainer.learning_rate)\n",
        "\n",
        "            rcnn_task = ForwardBackwardTask(self.net, trainer, rpn_cls_loss, rpn_box_loss, rcnn_cls_loss,\n",
        "                                            rcnn_box_loss, mix_ratio=1.0, amp_enabled=self.amp)\n",
        "            executor = Parallel(self.executor_threads, rcnn_task) if not self.horovod else None\n",
        "            mix_ratio = 1.0\n",
        "            if not self.disable_hybridization:\n",
        "                self.hybridize(static_alloc=self.static_alloc)\n",
        "            if self.mixup:\n",
        "                # TODO(zhreshold) only support evenly mixup now, target generator needs to be modified otherwise\n",
        "                self.train_data._dataset._data.set_mixup(np.random.uniform, 0.5, 0.5)\n",
        "                mix_ratio = 0.5\n",
        "                if epoch >= self.epochs - self.no_mixup_epochs:\n",
        "                    self.train_data._dataset._data.set_mixup(None)\n",
        "                    mix_ratio = 1.0\n",
        "\n",
        "            experiment.log_metric('learning_rate', epoch, trainer.learning_rate)\n",
        "            if self.optimizer == 'sgd':\n",
        "              while lr_steps and epoch >= lr_steps[0]:\n",
        "                  new_lr = trainer.learning_rate * lr_decay\n",
        "                  lr_steps.pop(0)\n",
        "                  trainer.set_learning_rate(new_lr)\n",
        "                  print(\"[Epoch {}] Set learning rate to {}\".format(epoch, new_lr))#logger.info\n",
        "            for metric in metrics:\n",
        "                metric.reset()\n",
        "            tic = time.time()\n",
        "            btic = time.time()\n",
        "            base_lr = trainer.learning_rate\n",
        "            rcnn_task.mix_ratio = mix_ratio\n",
        "            for i, batch in enumerate(self.train_data):\n",
        "                if epoch == 0 and i <= lr_warmup:\n",
        "                    # adjust based on real percentage\n",
        "                    new_lr = base_lr * self.get_lr_at_iter(i / lr_warmup, self.lr_warmup_factor)\n",
        "                    if new_lr != trainer.learning_rate:\n",
        "                        if i % self.log_interval == 0:\n",
        "                            print(\n",
        "                                '[Epoch 0 Iteration {}] Set learning rate to {}'.format(i, new_lr))#logger.info\n",
        "                        trainer.set_learning_rate(new_lr)\n",
        "                batch = self.split_and_load(batch, ctx_list=self.ctx)\n",
        "                metric_losses = [[] for _ in metrics]\n",
        "                add_losses = [[] for _ in metrics2]\n",
        "                if executor is not None:\n",
        "                    for data in zip(*batch):\n",
        "                        executor.put(data)\n",
        "                for j in range(len(self.ctx)):\n",
        "                    if executor is not None:\n",
        "                        result = executor.get()\n",
        "                    else:\n",
        "                        result = rcnn_task.forward_backward(list(zip(*batch))[0])\n",
        "\n",
        "                    for k in range(len(metric_losses)):\n",
        "                        metric_losses[k].append(result[k])\n",
        "                    for k in range(len(add_losses)):\n",
        "                        add_losses[k].append(result[len(metric_losses) + k])\n",
        "                for metric, record in zip(metrics, metric_losses):\n",
        "                    metric.update(0, record)\n",
        "                for metric, records in zip(metrics2, add_losses):\n",
        "                    for pred in records:\n",
        "                        metric.update(pred[0], pred[1])\n",
        "                trainer.step(self.batch_size)\n",
        "\n",
        "                # update metrics        #  (not self.horovod or hvd.rank() == 0) and  _k_\n",
        "                if self.log_interval \\\n",
        "                        and not (i + 1) % self.log_interval:\n",
        "                    msg = ','.join(\n",
        "                        ['{}={:.3f}'.format(*metric.get()) for metric in metrics + metrics2])\n",
        "                    print('[Epoch {}][Batch {}], Speed: {:.3f} samples/sec, {}'.format(\n",
        "                        epoch, i, self.log_interval * self.batch_size / (time.time() - btic), msg)) #logger.info\n",
        "                    btic = time.time()\n",
        "\n",
        "            # if (not self.horovod) or hvd.rank() == 0:\n",
        "            msg = ','.join(['{}={:.3f}'.format(*metric.get()) for metric in metrics])\n",
        "            print('[Epoch {}] Training cost: {:.3f}, {}'.format(\n",
        "                epoch, (time.time() - tic), msg)) #logger.info\n",
        "            \n",
        "            self.validate_main(epoch)#map_name, mean_ap = self.validate(self.net, self.val_data, self.ctx, self.val_metric)\n",
        " \n",
        "        print(\"Traning... OK\")    \n",
        "            \n",
        "    def train(self):\n",
        "        lr_decay = self.lr_decay\n",
        "        lr_decay_epoch = self.lr_decay_epoch        \n",
        "        optimizer = self.optimizer\n",
        "        network = self.network\n",
        "\n",
        "        # Gluon-CV requires you to create and load the parameters of your model first on \n",
        "        # the CPU - so specify ctx=None - and when all that is done you move the \n",
        "        # whole model on the GPU with:\n",
        "        self.net.collect_params().reset_ctx(self.ctx)\n",
        "\n",
        "        # # First create the trainer. Obs: you should reset_ctx before creating the optimizer\n",
        "        # self.create_optimizer()\n",
        "\n",
        "        # speeds up the training process\n",
        "        # Check: https://mxnet.apache.org/api/python/docs/tutorials/performance/backend/amp.html\n",
        "        # trainer = self.trainer\n",
        "        # amp.init_trainer(trainer)\n",
        "\n",
        "        if network == 'ssd':\n",
        "          # First create the trainer. Obs: you should reset_ctx before creating the optimizer\n",
        "            self.create_optimizer()\n",
        "            self.ssd_train()\n",
        "        elif network == 'yolo':\n",
        "          # First create the trainer. Obs: you should reset_ctx before creating the optimizer\n",
        "            self.create_optimizer()\n",
        "            self.yolo_train()\n",
        "        elif self.net_type =='faster':\n",
        "            self.faster_train()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtDYBNbDuOw_",
        "colab_type": "text"
      },
      "source": [
        "# Faster RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEhS8oQWs9wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"\"\"Train Faster-RCNN end to end.\"\"\"\n",
        "# import argparse\n",
        "# import os\n",
        "\n",
        "# disable autotune\n",
        "\n",
        "\n",
        "# try:\n",
        "#     import horovod.mxnet as hvd\n",
        "# except ImportError:\n",
        "#     hvd = None\n",
        "\n",
        "\n",
        "class Faster_rcnn(training_network):\n",
        "    def __init__(self,network = 'resnet50_v1b', dataset = 'voc',num_workers = 4,batch_size = 1,gpu = 0,epochs = 20,\n",
        "                 resume = '',start_epoch = 0,lr = 0.001,lr_decay = 0.1,lr_decay_epoch= '14,20',lr_warmup = -1, beta1=0.9, beta2=0.999, epsilon=1e-08,\n",
        "                 lr_warmup_factor = 1. / 3.,momentum = 0.9, validation_threshold=0.5, nms_threshold=0.5,wd = 5e-4,log_interval = 1,save_interval = 1, optimizer = 'sgd',\n",
        "                 val_interval = 1,exp = False,train_file = 'train.rec',val_file = 'val.rec',ctx = 'gpu',save_prefix = 'faster_cnn_model_', x_id=None):\n",
        "        self.x_id = x_id\n",
        "        self.old_save = None\n",
        "        self.net_type = 'faster'\n",
        "        self.batch_size=batch_size #\n",
        "        self.num_workers=num_workers#\n",
        "        self.learning_rate = lr#\n",
        "        self.lr = lr#\n",
        "        self.weight_decay = wd#\n",
        "        self.wd = wd#\n",
        "        self.momentum = momentum#\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_decay = lr_decay#\n",
        "        self.lr_decay_epoch = lr_decay_epoch#\n",
        "        self.val_interval = val_interval#\n",
        "        self.start_epoch = start_epoch#\n",
        "        self.epochs = epochs#\n",
        "        self.log_interval = log_interval#\n",
        "        self.save_interval = save_interval#\n",
        "        self.resume = resume#\n",
        "        self.validation_threshold = validation_threshold\n",
        "        self.nms_threshold = nms_threshold\n",
        "        self.network = network#\n",
        "        self.dataset = dataset#\n",
        "        self.beta1=beta1\n",
        "        self.beta2=beta2\n",
        "        self.epsilon=epsilon\n",
        "        self.trainer = None\n",
        "        \n",
        "        self.gpu = gpu#\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        self.lr_warmup = lr_warmup#\n",
        "        self.lr_warmup_factor = lr_warmup_factor#\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        self.mixup = False\n",
        "        self.no_mixup_epochs = 20\n",
        "        self.norm_layer = None\n",
        "        self.rpn_smoothl1_rho = 1. / 9.\n",
        "        self.rcnn_smoothl1_rho = 1\n",
        "        self.use_fpn = False\n",
        "        self.disable_hybridization = True\n",
        "        self.static_alloc = True\n",
        "        self.amp = False\n",
        "        self.horovod = False\n",
        "        self.executor_threads = 2\n",
        "        self.kv_store = 'nccl'\n",
        "        self.experiment = exp\n",
        "\n",
        "        self.save_prefix = save_prefix\n",
        "        self.train_file = train_file\n",
        "        self.val_file = val_file\n",
        "        self.validation_threshold = 0.5\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.val_metric = None\n",
        "        self.classes = ['bar_clamp', 'gear_box', 'vase', 'part_1', 'part_3', 'nozzle', 'pawn', 'turbine_housing']\n",
        "        #Configuração da rede\n",
        "        self.custom_model = False\n",
        "        self.no_pretrained_base = True\n",
        "        self.num_fpn_filters = 256\n",
        "        self.num_box_head_conv = 4\n",
        "        self.num_box_head_conv_filters = 256\n",
        "        self.num_box_head_dense_filters = 1024\n",
        "        self.image_short = 800\n",
        "        self.image_max_size = 1033\n",
        "        self.nms_thresh = 0.5\n",
        "        self.nms_topk = -1\n",
        "        self.post_nms = -1\n",
        "        self.roi_mode = 'align'\n",
        "        self.roi_size = '7,7'\n",
        "        self.strides = '4,8,16,32,64'\n",
        "        self.clip = 4.14\n",
        "        self.rpn_channel = 256\n",
        "        self.anchor_base_size = 16\n",
        "        self.anchor_aspect_ratio = '0.5,1,2'\n",
        "        self.anchor_scales = '2,4,8,16,32'\n",
        "        self.anchor_alloc_size = '384,384'\n",
        "        self.rpn_ms_thresh = '0.7'\n",
        "        self.rpn_train_pre_nms = 12000\n",
        "        self.rpn_train_post_nms = 2000\n",
        "        self.rpn_test_pre_nms = 6000\n",
        "        self.rpn_test_post_nms = 1000\n",
        "        self.rpn_min_size= 1\n",
        "        self.rcnn_num_sample = 512\n",
        "        self.rcnn_pos_iou_thresh = 0.5\n",
        "        self.rcnn_pos_ratio = 0.25\n",
        "        self.max_num_gt = 100\n",
        "        self.best_map=0\n",
        "\n",
        "        if ctx == 'cpu':\n",
        "            self.ctx = [mx.cpu()]\n",
        "        elif ctx == 'gpu':\n",
        "            self.ctx = [mx.gpu(self.gpu)]\n",
        "        else:\n",
        "            raise ValueError('Invalid context.')\n",
        "\n",
        "        # fix seed for mxnet, numpy and python builtin random generator.\n",
        "        gutils.random.seed(233)\n",
        "\n",
        "        self.net = None\n",
        "\n",
        "        self.get_dataset()\n",
        "        self.create_network()\n",
        "        self.data_loader()\n",
        "\n",
        "    # def get_dataset(self):\n",
        "\n",
        "    #     self.train_dataset = gdata.RecordFileDetection(self.train_file)\n",
        "    #     self.val_dataset = gdata.RecordFileDetection(self.val_file)\n",
        "    #     self.val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=self.classes)\n",
        "    #     print(\"Dataset... OK\")\n",
        "\n",
        "    def create_network(self):\n",
        "        kwargs = {}\n",
        "        module_list = []\n",
        "        if self.use_fpn:\n",
        "            module_list.append('fpn')\n",
        "        if self.norm_layer is not None:\n",
        "            module_list.append(self.norm_layer)\n",
        "            if self.norm_layer == 'syncbn':\n",
        "                kwargs['num_devices'] = len(self.ctx)\n",
        "\n",
        "        num_gpus =len(self.ctx) # hvd.size() if self.horovod else __k__\n",
        "        net_name = '_'.join(('faster_rcnn', *module_list, self.network, self.dataset))\n",
        "        if self.custom_model:\n",
        "            self.use_fpn = True\n",
        "            net_name = '_'.join(('custom_faster_rcnn_fpn', self.network, self.dataset))\n",
        "            if self.norm_layer == 'syncbn':\n",
        "                norm_layer = gluon.contrib.nn.SyncBatchNorm\n",
        "                norm_kwargs = {'num_devices': len(self.ctx)}\n",
        "                sym_norm_layer = mx.sym.contrib.SyncBatchNorm\n",
        "                sym_norm_kwargs = {'ndev': len(self.ctx)}\n",
        "            elif self.norm_layer == 'gn':\n",
        "                norm_layer = gluon.nn.GroupNorm\n",
        "                norm_kwargs = {'groups': 8}\n",
        "                sym_norm_layer = mx.sym.GroupNorm\n",
        "                sym_norm_kwargs = {'groups': 8}\n",
        "            else:\n",
        "                norm_layer = gluon.nn.BatchNorm\n",
        "                norm_kwargs = None\n",
        "                sym_norm_layer = None\n",
        "                sym_norm_kwargs = None\n",
        "            classes = self.classes\n",
        "            self.net = get_model('custom_faster_rcnn_fpn', classes=classes, transfer=None,\n",
        "                            dataset=self.dataset, pretrained_base=not self.no_pretrained_base,\n",
        "                            base_network_name=self.network, norm_layer=norm_layer,\n",
        "                            norm_kwargs=norm_kwargs, sym_norm_kwargs=sym_norm_kwargs,\n",
        "                            num_fpn_filters=self.num_fpn_filters,\n",
        "                            num_box_head_conv= self.num_box_head_conv,\n",
        "                            num_box_head_conv_filters=self.num_box_head_conv_filters,\n",
        "                            num_box_head_dense_filters=self.num_box_head_dense_filters,\n",
        "                            short=self.image_short, max_size=self.image_max_size, min_stage=2,\n",
        "                            max_stage=6, nms_thresh=self.nms_thresh, nms_topk=self.nms_topk,\n",
        "                            post_nms=self.post_nms, roi_mode=self.roi_mode, roi_size=self.roi_size,\n",
        "                            strides=self.strides, clip=self.clip, rpn_channel=self.rpn_channel,\n",
        "                            base_size=self.anchor_base_size, scales=self.anchor_scales,\n",
        "                            ratios=self.anchor_aspect_ratio, alloc_size=self.anchor_alloc_size,\n",
        "                            rpn_nms_thresh=self.rpn_nms_thresh,\n",
        "                            rpn_train_pre_nms=self.rpn_train_pre_nms,\n",
        "                            rpn_train_post_nms=self.rpn_train_post_nms,\n",
        "                            rpn_test_pre_nms=self.rpn_test_pre_nms,\n",
        "                            rpn_test_post_nms=self.rpn_test_post_nms, rpn_min_size=self.rpn_min_size,\n",
        "                            per_device_batch_size=self.batch_size // num_gpus,\n",
        "                            num_sample=self.rcnn_num_samples, pos_iou_thresh=self.rcnn_pos_iou_thresh,\n",
        "                            pos_ratio=self.rcnn_pos_ratio, max_num_gt=self.max_num_gt)\n",
        "        else:\n",
        "            self.net = get_model(net_name, pretrained_base=True,\n",
        "                            per_device_batch_size=self.batch_size // num_gpus, **kwargs)\n",
        "        # self.save_prefix += net_name\n",
        "        if self.resume.strip():\n",
        "            self.net.load_parameters(self.resume.strip())\n",
        "        else:\n",
        "            for param in self.net.collect_params().values():\n",
        "                if param._data is not None:\n",
        "                    continue\n",
        "                param.initialize()\n",
        "        self.net.collect_params().reset_ctx(self.ctx)\n",
        "        print(\"Network... OK\")\n",
        "\n",
        "    def data_loader(self):\n",
        "        \"\"\"Get dataloader.\"\"\"\n",
        "        train_transform = FasterRCNNDefaultTrainTransform\n",
        "        val_transform = FasterRCNNDefaultValTransform\n",
        "        train_bfn = FasterRCNNTrainBatchify(self.net, len(self.ctx))\n",
        "        if hasattr(self.train_dataset, 'get_im_aspect_ratio'):\n",
        "            im_aspect_ratio = self.train_dataset.get_im_aspect_ratio()\n",
        "        else:\n",
        "            im_aspect_ratio = [1.] * len(self.train_dataset)\n",
        "        train_sampler = \\\n",
        "            gcv.nn.sampler.SplitSortedBucketSampler(im_aspect_ratio, self.batch_size,\n",
        "                                                    num_parts=1, #hvd.size() if self.horovod else _k_\n",
        "                                                    part_index=0, #hvd.rank() if self.horovod else _k_ \n",
        "                                                    shuffle=True)\n",
        "        self.train_data = mx.gluon.data.DataLoader(self.train_dataset.transform(\n",
        "            train_transform(self.net.short, self.net.max_size, self.net, ashape=self.net.ashape, multi_stage=self.use_fpn)),\n",
        "            batch_sampler=train_sampler, batchify_fn=train_bfn, num_workers=self.num_workers)\n",
        "        val_bfn = Tuple(*[Append() for _ in range(3)])\n",
        "        short = self.net.short[-1] if isinstance(self.net.short, (tuple, list)) else self.net.short\n",
        "        # validation use 1 sample per device\n",
        "        self.val_data = mx.gluon.data.DataLoader(\n",
        "            self.val_dataset.transform(val_transform(short, self.net.max_size)), len(self.ctx), False,\n",
        "            batchify_fn=val_bfn, last_batch='keep', num_workers=self.num_workers)\n",
        "        print(\"Dataloader... OK\")\n",
        "\n",
        "    def get_lr_at_iter(self,alpha, lr_warmup_factor=1. / 3.):\n",
        "        return lr_warmup_factor * (1 - alpha) + alpha\n",
        "\n",
        "    def split_and_load(self,batch, ctx_list):\n",
        "        \"\"\"Split data to 1 batch each device.\"\"\"\n",
        "        new_batch = []\n",
        "        for i, data in enumerate(batch):\n",
        "            if isinstance(data, (list, tuple)):\n",
        "                new_data = [x.as_in_context(ctx) for x, ctx in zip(data, ctx_list)]\n",
        "            else:\n",
        "                new_data = [data.as_in_context(ctx_list[0])]\n",
        "            new_batch.append(new_data)\n",
        "        return new_batch\n",
        "    \n",
        "\n",
        "#FASTER  ##,net, val_data, ctx, val_metric\n",
        "    def validate(self):\n",
        "        \"\"\"Test on validation dataset.\"\"\"\n",
        "        val_data = self.val_data\n",
        "        ctx = self.ctx\n",
        "        val_metric = self.val_metric\n",
        "        nms_threshold = self.nms_threshold\n",
        "        validation_threshold = self.validation_threshold\n",
        "\n",
        "        clipper = gcv.nn.bbox.BBoxClipToImage()\n",
        "        val_metric.reset()\n",
        "        # if not self.disable_hybridization:\n",
        "            # input format is differnet than training, thus rehybridization is needed.\n",
        "        # self.net.hybridize(static_alloc=self.static_alloc)\n",
        "        for batch in val_data:\n",
        "            batch = self.split_and_load(batch, ctx_list=ctx)\n",
        "            pred_bboxes_list = []\n",
        "            pred_label_list = []\n",
        "            pred_scores_list = []\n",
        "            gt_bboxes_list = []\n",
        "            gt_label_list = []\n",
        "            # gt_difficults = []\n",
        "            for x, y, im_scale in zip(*batch):\n",
        "                # get prediction results\n",
        "                ids, scores, bboxes = self.net(x)\n",
        "                pred_label_list.append(ids)\n",
        "                pred_scores_list.append(scores)\n",
        "                # clip to image size\n",
        "                pred_bboxes_list.append(clipper(bboxes, x))\n",
        "                # rescale to original resolution\n",
        "                im_scale = im_scale.reshape((-1)).asscalar()\n",
        "                pred_bboxes_list[-1] *= im_scale\n",
        "                # split ground truths\n",
        "                gt_label_list.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
        "                gt_bboxes_list.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
        "                gt_bboxes_list[-1] *= im_scale\n",
        "                # gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\n",
        "\n",
        "            # update metric\n",
        "            for pred_bbox, pred_id, pred_score, gt_bbox, gt_id in zip(pred_bboxes_list, pred_label_list,\n",
        "                                                                            pred_scores_list, gt_bboxes_list,\n",
        "                                                                            gt_label_list):\n",
        "                val_metric.update(pred_bbox, pred_id, pred_score, gt_bbox, gt_id)\n",
        "\n",
        "        num_of_classes = len(self.classes)\n",
        "        # total number of correct prediction by class\n",
        "        tp = [0] * num_of_classes\n",
        "        # false positives by class\n",
        "        fp = [0] * num_of_classes\n",
        "        # count the number of gt by class\n",
        "        gt_by_class = [0] * num_of_classes\n",
        "        # rec and prec by class\n",
        "        rec_by_class = [0] * num_of_classes\n",
        "        prec_by_class = [0] * num_of_classes\n",
        "        confusion_matrix = np.zeros((num_of_classes, num_of_classes))\n",
        "        for img in range(self.batch_size):\n",
        "              # count +1 for this class id. It will get the total number of gt by class\n",
        "              # It is useful when considering unbalanced datasets\n",
        "              for gt_idx in gt_label_list[0][img]:\n",
        "                  index = int(gt_idx.asnumpy()[0])\n",
        "                  gt_by_class[index] += 1\n",
        "          \n",
        "              for (pred_label, pred_bbox) in zip(pred_label_list[0][img], list(pred_bboxes_list[0][img])):\n",
        "                  pred_label = int(pred_label.asnumpy()[0])\n",
        "                  pred_bbox = pred_bbox.asnumpy()\n",
        "                  pred_bbox = np.expand_dims(pred_bbox, axis=0)\n",
        "                  match = 0\n",
        "                  for (gt_bbox_label, gt_bbox_coordinates) in zip(gt_label_list[0][img], list(gt_bboxes_list[0][img])):\n",
        "                      gt_bbox_coord = gt_bbox_coordinates.asnumpy()\n",
        "                      gt_bbox_coord = np.expand_dims(gt_bbox_coord, axis=0)\n",
        "                      gt_bbox_label = int(gt_bbox_label.asnumpy()[0])\n",
        "                      iou = bbox_iou(pred_bbox, gt_bbox_coord)\n",
        "                      \n",
        "                      # Correct inference\n",
        "                      if iou > validation_threshold and pred_label == gt_bbox_label:\n",
        "                          confusion_matrix[gt_bbox_label][pred_label] += 1\n",
        "                          tp[gt_bbox_label] += 1 # Correct classification\n",
        "                          match = 1\n",
        "                      # Incorrect inference - missed the correct class but put the bounding box in other class\n",
        "                      elif iou > validation_threshold:\n",
        "                          confusion_matrix[gt_bbox_label][pred_label] += 1\n",
        "                          fp[pred_label] += 1\n",
        "                          match = 1\n",
        "                      \n",
        "                  if not match:\n",
        "                      fp[pred_label] += 1\n",
        "                              \n",
        "        # calculate the Recall and Precision by class\n",
        "        tp = np.array(tp) # we can also sum the matrix diagonal\n",
        "        fp = np.array(fp)\n",
        "        fp_sum = sum(fp)\n",
        "        tp_sum = sum(tp)\n",
        "\n",
        "        # rec and prec according to the micro averaging\n",
        "        for i, (gt_value, tp_value) in enumerate(zip(gt_by_class, tp)):\n",
        "            rec_by_class[i] += tp_value/gt_value\n",
        "            # If an element of fp + tp is 0,\n",
        "            # the corresponding element of prec[l] is nan.\n",
        "            with np.errstate(divide='ignore', invalid='ignore'):\n",
        "                prec_by_class[i] += tp_value/(tp_value+fp[i])\n",
        "\n",
        "        return val_metric.get(), rec_by_class, prec_by_class\n",
        "\n",
        "    def create_optimizer(self, kv):\n",
        "        optimizer = self.optimizer\n",
        "        momentum = self.momentum\n",
        "        wd = self.wd\n",
        "        lr = self.lr\n",
        "        beta1 = self.beta1\n",
        "        beta2 = self.beta2\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        if optimizer == 'sgd':\n",
        "            optimizer_params = {'multi_precision' : True, 'learning_rate': lr, \n",
        "                                          'wd': wd, 'momentum': momentum}\n",
        "            # wd: The weight decay (or L2 regularization) coefficient.\n",
        "            \n",
        "        elif optimizer == 'adam':\n",
        "            optimizer_params = {'multi_precision' : True, 'learning_rate': lr, 'beta1': beta1, 'beta2': beta2,\n",
        "                                          'epsilon': epsilon}\n",
        "    \n",
        "        self.trainer = gluon.Trainer(self.net.collect_train_params(), optimizer, optimizer_params\n",
        "                                    , update_on_kvstore=(False if False else None), kvstore=kv) #self.amp"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhm3jG8jtQ4p",
        "colab_type": "text"
      },
      "source": [
        "# Função Main "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi38NtjktQSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a966e68d-aa64-43a7-e412-44cc3efb32d6"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  try:\n",
        "    neptune.init('caioviturino/IJR2020')\n",
        "    #'yolo3_darknet53_coco'\n",
        "    #'faster_rcnn_resnet50_v1b_voc'\n",
        "    PARAMS = {'model_name': 'faster_rcnn_resnet50_v1b_voc', \n",
        "              'ctx': 'gpu',\n",
        "              'lr_decay_epoch': '30,50',\n",
        "              'lr': 1e-4, # 0.0001,\n",
        "              'lr_decay': 0.1,\n",
        "              'batch_size': 16,\n",
        "              'epochs': 60, #80\n",
        "              'optimizer': 'adam', #https://mxnet.apache.org/versions/1.6/api/python/docs/tutorials/packages/optimizer/index.html\n",
        "              'wd': 5e-4, # 0.0005, # sgd parameter\n",
        "              'momentum': 0.9, # 0.9, # sgd parameter\n",
        "              'beta1': 0.9, # 0.9, # adam parameter\n",
        "              'beta2': 0.999, #0.999, # adam parameter\n",
        "              'epsilon': 1e-08, # 1e-08, # adam parameter\n",
        "              'validation_threshold': 0.5,\n",
        "              'nms_threshold': 0.5\n",
        "              }\n",
        "\n",
        "    # create experiment (all parameters are optional)\n",
        "    experiment = neptune.create_experiment(name=PARAMS['model_name'],\n",
        "                                           params=PARAMS,\n",
        "                                           tags=[PARAMS['model_name'], PARAMS['optimizer'], 'kleber'])\n",
        "    \n",
        "    \n",
        "    print('Experiment ID = ' + experiment.id + '\\n Net= '+ PARAMS['model_name'])\n",
        "\n",
        "\n",
        "    ## TODO : Trocar == por *contains*\n",
        "    \n",
        "    if PARAMS['model_name'] == 'faster_rcnn_resnet50_v1b_voc':\n",
        "      train_loc = 'drive/My Drive/UFBA/Doutorado/Ssd_test/Dataset/train_teste_7_300_300.rec'\n",
        "      val_loc = 'drive/My Drive/UFBA/Doutorado/Ssd_test/Dataset/val_teste_7_300_300.rec'\n",
        "      save_loc = 'drive/My Drive/UFBA/Doutorado/Ssd_test/checkpoints'\n",
        "      fast = Faster_rcnn(train_file=train_loc, val_file=val_loc,save_prefix=save_loc, ctx=PARAMS['ctx'], \\\n",
        "                         lr_decay_epoch=PARAMS['lr_decay_epoch'], lr=PARAMS['lr'], \\\n",
        "                         lr_decay=PARAMS['lr_decay'], batch_size=1, epochs=PARAMS['epochs'], \\\n",
        "                         optimizer=PARAMS['optimizer'],  \\\n",
        "                         validation_threshold=PARAMS['validation_threshold'], nms_threshold=PARAMS['nms_threshold'], \\\n",
        "                         beta1=PARAMS['beta1'], beta2=PARAMS['beta2'], epsilon=PARAMS['epsilon'], \\\n",
        "                         wd=PARAMS['wd'], momentum=PARAMS['momentum'], x_id = experiment.id) \n",
        "                         #exp = experiment\n",
        "      # print('\\n'.join(str(a) for a in dir(fast)))\n",
        "      fast.faster_train()\n",
        "      os.environ['MXNET_CUDNN_AUTOTUNE_DEFAULT'] = '0'\n",
        "      os.environ['MXNET_GPU_MEM_POOL_TYPE'] = 'Round'\n",
        "      os.environ['MXNET_GPU_MEM_POOL_ROUND_LINEAR_CUTOFF'] = '26'\n",
        "      os.environ['MXNET_EXEC_BULK_EXEC_MAX_NODE_TRAIN_FWD'] = '999'\n",
        "      os.environ['MXNET_EXEC_BULK_EXEC_MAX_NODE_TRAIN_BWD'] = '25'\n",
        "      os.environ['MXNET_GPU_COPY_NTHREADS'] = '1'\n",
        "      os.environ['MXNET_OPTIMIZER_AGGREGATION_SIZE'] = '54'\n",
        "    else:\n",
        "      train_object = training_network(model=PARAMS['model_name'], ctx=PARAMS['ctx'], \\\n",
        "                                          lr_decay_epoch=PARAMS['lr_decay_epoch'], lr=PARAMS['lr'], \\\n",
        "                                          lr_decay=PARAMS['lr_decay'], batch_size=PARAMS['batch_size'], epochs=PARAMS['epochs'], \\\n",
        "                                          optimizer=PARAMS['optimizer'],  \\\n",
        "                                          validation_threshold=PARAMS['validation_threshold'], nms_threshold=PARAMS['nms_threshold'], \\\n",
        "                                          beta1=PARAMS['beta1'], beta2=PARAMS['beta2'], epsilon=PARAMS['epsilon'], \\\n",
        "                                          wd=PARAMS['wd'], momentum=PARAMS['momentum'], x_id = experiment.id)\n",
        "  # exp=experiment,\n",
        "      train_object.get_dataset()\n",
        "      # train_object.show_summary()\n",
        "      # Loads the dataset according to the batch size and num_workers\n",
        "      train_object.get_dataloader()\n",
        "      # training\n",
        "      train_object.train()\n",
        "  except:\n",
        "    raise\n",
        "  finally:\n",
        "    neptune.stop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ui.neptune.ai/caioviturino/IJR2020/e/SAN-345\n",
            "Experiment ID = SAN-345\n",
            " Net= faster_rcnn_resnet50_v1b_voc\n",
            "Downloading /root/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55344/55344 [00:02<00:00, 22991.14KB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Network... OK\n",
            "Dataloader... OK\n",
            "Train start\n",
            "Start training from [Epoch 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter \"fasterrcnn0_rpn0_rpnanchorgenerator0_anchor_\" does not support grad_req other than \"null\", and new value \"write\" is ignored.\n",
            "  'is ignored.'.format(self.name, req))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0][Batch 0], Speed: 0.297 samples/sec, RPN_Conf=0.686,RPN_SmoothL1=0.028,RCNN_CrossEntropy=2.976,RCNN_SmoothL1=0.019,RPNAcc=0.531,RPNL1Loss=0.596,RCNNAcc=0.023,RCNNL1Loss=0.273\n",
            "[Epoch 0][Batch 1], Speed: 0.990 samples/sec, RPN_Conf=0.649,RPN_SmoothL1=0.032,RCNN_CrossEntropy=2.540,RCNN_SmoothL1=0.166,RPNAcc=0.730,RPNL1Loss=0.649,RCNNAcc=0.395,RCNNL1Loss=1.328\n",
            "[Epoch 0][Batch 2], Speed: 2.602 samples/sec, RPN_Conf=0.604,RPN_SmoothL1=0.030,RCNN_CrossEntropy=2.097,RCNN_SmoothL1=0.234,RPNAcc=0.801,RPNL1Loss=0.598,RCNNAcc=0.526,RCNNL1Loss=1.526\n",
            "[Epoch 0][Batch 3], Speed: 1.436 samples/sec, RPN_Conf=0.558,RPN_SmoothL1=0.029,RCNN_CrossEntropy=1.818,RCNN_SmoothL1=0.311,RPNAcc=0.840,RPNL1Loss=0.596,RCNNAcc=0.582,RCNNL1Loss=1.752\n",
            "[Epoch 0][Batch 4], Speed: 1.564 samples/sec, RPN_Conf=0.519,RPN_SmoothL1=0.032,RCNN_CrossEntropy=1.645,RCNN_SmoothL1=0.362,RPNAcc=0.857,RPNL1Loss=0.616,RCNNAcc=0.616,RCNNL1Loss=1.881\n",
            "[Epoch 0][Batch 5], Speed: 1.449 samples/sec, RPN_Conf=0.477,RPN_SmoothL1=0.032,RCNN_CrossEntropy=1.534,RCNN_SmoothL1=0.386,RPNAcc=0.872,RPNL1Loss=0.600,RCNNAcc=0.638,RCNNL1Loss=1.914\n",
            "[Epoch 0][Batch 6], Speed: 1.325 samples/sec, RPN_Conf=0.431,RPN_SmoothL1=0.030,RCNN_CrossEntropy=1.430,RCNN_SmoothL1=0.388,RPNAcc=0.885,RPNL1Loss=0.599,RCNNAcc=0.654,RCNNL1Loss=1.861\n",
            "[Epoch 0][Batch 7], Speed: 1.489 samples/sec, RPN_Conf=0.391,RPN_SmoothL1=0.030,RCNN_CrossEntropy=1.324,RCNN_SmoothL1=0.386,RPNAcc=0.895,RPNL1Loss=0.618,RCNNAcc=0.675,RCNNL1Loss=1.866\n",
            "[Epoch 0][Batch 8], Speed: 1.638 samples/sec, RPN_Conf=0.364,RPN_SmoothL1=0.033,RCNN_CrossEntropy=1.267,RCNN_SmoothL1=0.413,RPNAcc=0.900,RPNL1Loss=0.655,RCNNAcc=0.688,RCNNL1Loss=1.949\n",
            "[Epoch 0][Batch 9], Speed: 1.350 samples/sec, RPN_Conf=0.335,RPN_SmoothL1=0.032,RCNN_CrossEntropy=1.220,RCNN_SmoothL1=0.431,RPNAcc=0.906,RPNL1Loss=0.658,RCNNAcc=0.698,RCNNL1Loss=1.997\n",
            "[Epoch 0][Batch 10], Speed: 1.402 samples/sec, RPN_Conf=0.319,RPN_SmoothL1=0.035,RCNN_CrossEntropy=1.174,RCNN_SmoothL1=0.438,RPNAcc=0.909,RPNL1Loss=0.692,RCNNAcc=0.706,RCNNL1Loss=2.003\n",
            "[Epoch 0][Batch 11], Speed: 1.425 samples/sec, RPN_Conf=0.305,RPN_SmoothL1=0.035,RCNN_CrossEntropy=1.133,RCNN_SmoothL1=0.451,RPNAcc=0.911,RPNL1Loss=0.661,RCNNAcc=0.715,RCNNL1Loss=2.038\n",
            "[Epoch 0][Batch 12], Speed: 1.478 samples/sec, RPN_Conf=0.286,RPN_SmoothL1=0.034,RCNN_CrossEntropy=1.094,RCNN_SmoothL1=0.461,RPNAcc=0.917,RPNL1Loss=0.665,RCNNAcc=0.722,RCNNL1Loss=2.062\n",
            "[Epoch 0][Batch 13], Speed: 1.425 samples/sec, RPN_Conf=0.275,RPN_SmoothL1=0.036,RCNN_CrossEntropy=1.075,RCNN_SmoothL1=0.468,RPNAcc=0.919,RPNL1Loss=0.673,RCNNAcc=0.723,RCNNL1Loss=2.077\n",
            "[Epoch 0][Batch 14], Speed: 1.378 samples/sec, RPN_Conf=0.262,RPN_SmoothL1=0.037,RCNN_CrossEntropy=1.040,RCNN_SmoothL1=0.476,RPNAcc=0.923,RPNL1Loss=0.677,RCNNAcc=0.727,RCNNL1Loss=2.098\n",
            "[Epoch 0][Batch 15], Speed: 1.418 samples/sec, RPN_Conf=0.248,RPN_SmoothL1=0.036,RCNN_CrossEntropy=1.012,RCNN_SmoothL1=0.486,RPNAcc=0.927,RPNL1Loss=0.679,RCNNAcc=0.729,RCNNL1Loss=2.127\n",
            "[Epoch 0][Batch 16], Speed: 1.495 samples/sec, RPN_Conf=0.235,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.982,RCNN_SmoothL1=0.492,RPNAcc=0.930,RPNL1Loss=0.679,RCNNAcc=0.736,RCNNL1Loss=2.139\n",
            "[Epoch 0][Batch 17], Speed: 1.373 samples/sec, RPN_Conf=0.229,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.973,RCNN_SmoothL1=0.497,RPNAcc=0.932,RPNL1Loss=0.683,RCNNAcc=0.737,RCNNL1Loss=2.154\n",
            "[Epoch 0][Batch 18], Speed: 1.402 samples/sec, RPN_Conf=0.219,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.949,RCNN_SmoothL1=0.508,RPNAcc=0.935,RPNL1Loss=0.691,RCNNAcc=0.741,RCNNL1Loss=2.191\n",
            "[Epoch 0][Batch 19], Speed: 1.441 samples/sec, RPN_Conf=0.211,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.928,RCNN_SmoothL1=0.511,RPNAcc=0.937,RPNL1Loss=0.700,RCNNAcc=0.743,RCNNL1Loss=2.196\n",
            "[Epoch 0][Batch 20], Speed: 1.432 samples/sec, RPN_Conf=0.203,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.904,RCNN_SmoothL1=0.515,RPNAcc=0.939,RPNL1Loss=0.694,RCNNAcc=0.749,RCNNL1Loss=2.206\n",
            "[Epoch 0][Batch 21], Speed: 1.418 samples/sec, RPN_Conf=0.195,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.883,RCNN_SmoothL1=0.519,RPNAcc=0.941,RPNL1Loss=0.688,RCNNAcc=0.751,RCNNL1Loss=2.214\n",
            "[Epoch 0][Batch 22], Speed: 1.403 samples/sec, RPN_Conf=0.188,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.861,RCNN_SmoothL1=0.518,RPNAcc=0.944,RPNL1Loss=0.684,RCNNAcc=0.755,RCNNL1Loss=2.204\n",
            "[Epoch 0][Batch 23], Speed: 1.393 samples/sec, RPN_Conf=0.181,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.845,RCNN_SmoothL1=0.521,RPNAcc=0.946,RPNL1Loss=0.724,RCNNAcc=0.757,RCNNL1Loss=2.211\n",
            "[Epoch 0][Batch 24], Speed: 1.410 samples/sec, RPN_Conf=0.176,RPN_SmoothL1=0.040,RCNN_CrossEntropy=0.827,RCNN_SmoothL1=0.524,RPNAcc=0.947,RPNL1Loss=0.735,RCNNAcc=0.760,RCNNL1Loss=2.216\n",
            "[Epoch 0][Batch 25], Speed: 1.423 samples/sec, RPN_Conf=0.171,RPN_SmoothL1=0.040,RCNN_CrossEntropy=0.813,RCNN_SmoothL1=0.528,RPNAcc=0.948,RPNL1Loss=0.733,RCNNAcc=0.764,RCNNL1Loss=2.231\n",
            "[Epoch 0][Batch 26], Speed: 1.428 samples/sec, RPN_Conf=0.166,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.800,RCNN_SmoothL1=0.531,RPNAcc=0.950,RPNL1Loss=0.723,RCNNAcc=0.768,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 27], Speed: 1.394 samples/sec, RPN_Conf=0.161,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.783,RCNN_SmoothL1=0.532,RPNAcc=0.951,RPNL1Loss=0.718,RCNNAcc=0.771,RCNNL1Loss=2.237\n",
            "[Epoch 0][Batch 28], Speed: 1.454 samples/sec, RPN_Conf=0.156,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.769,RCNN_SmoothL1=0.532,RPNAcc=0.952,RPNL1Loss=0.712,RCNNAcc=0.774,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 29], Speed: 1.389 samples/sec, RPN_Conf=0.152,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.757,RCNN_SmoothL1=0.532,RPNAcc=0.954,RPNL1Loss=0.717,RCNNAcc=0.774,RCNNL1Loss=2.232\n",
            "[Epoch 0][Batch 30], Speed: 1.463 samples/sec, RPN_Conf=0.148,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.746,RCNN_SmoothL1=0.535,RPNAcc=0.955,RPNL1Loss=0.713,RCNNAcc=0.776,RCNNL1Loss=2.238\n",
            "[Epoch 0][Batch 31], Speed: 1.384 samples/sec, RPN_Conf=0.144,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.740,RCNN_SmoothL1=0.537,RPNAcc=0.956,RPNL1Loss=0.704,RCNNAcc=0.775,RCNNL1Loss=2.245\n",
            "[Epoch 0][Batch 32], Speed: 1.466 samples/sec, RPN_Conf=0.141,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.728,RCNN_SmoothL1=0.538,RPNAcc=0.957,RPNL1Loss=0.699,RCNNAcc=0.777,RCNNL1Loss=2.247\n",
            "[Epoch 0][Batch 33], Speed: 1.343 samples/sec, RPN_Conf=0.137,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.714,RCNN_SmoothL1=0.539,RPNAcc=0.958,RPNL1Loss=0.695,RCNNAcc=0.781,RCNNL1Loss=2.245\n",
            "[Epoch 0][Batch 34], Speed: 1.425 samples/sec, RPN_Conf=0.134,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.703,RCNN_SmoothL1=0.540,RPNAcc=0.959,RPNL1Loss=0.686,RCNNAcc=0.783,RCNNL1Loss=2.250\n",
            "[Epoch 0][Batch 35], Speed: 1.416 samples/sec, RPN_Conf=0.131,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.691,RCNN_SmoothL1=0.540,RPNAcc=0.960,RPNL1Loss=0.685,RCNNAcc=0.788,RCNNL1Loss=2.247\n",
            "[Epoch 0][Batch 36], Speed: 1.437 samples/sec, RPN_Conf=0.128,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.686,RCNN_SmoothL1=0.540,RPNAcc=0.961,RPNL1Loss=0.683,RCNNAcc=0.789,RCNNL1Loss=2.244\n",
            "[Epoch 0][Batch 37], Speed: 1.403 samples/sec, RPN_Conf=0.125,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.676,RCNN_SmoothL1=0.540,RPNAcc=0.962,RPNL1Loss=0.683,RCNNAcc=0.792,RCNNL1Loss=2.239\n",
            "[Epoch 0][Batch 38], Speed: 1.395 samples/sec, RPN_Conf=0.123,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.666,RCNN_SmoothL1=0.540,RPNAcc=0.962,RPNL1Loss=0.681,RCNNAcc=0.795,RCNNL1Loss=2.240\n",
            "[Epoch 0][Batch 39], Speed: 1.386 samples/sec, RPN_Conf=0.120,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.661,RCNN_SmoothL1=0.541,RPNAcc=0.963,RPNL1Loss=0.676,RCNNAcc=0.796,RCNNL1Loss=2.240\n",
            "[Epoch 0][Batch 40], Speed: 1.469 samples/sec, RPN_Conf=0.118,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.650,RCNN_SmoothL1=0.539,RPNAcc=0.964,RPNL1Loss=0.675,RCNNAcc=0.800,RCNNL1Loss=2.231\n",
            "[Epoch 0][Batch 41], Speed: 1.349 samples/sec, RPN_Conf=0.115,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.643,RCNN_SmoothL1=0.539,RPNAcc=0.965,RPNL1Loss=0.670,RCNNAcc=0.802,RCNNL1Loss=2.230\n",
            "[Epoch 0][Batch 42], Speed: 1.448 samples/sec, RPN_Conf=0.113,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.634,RCNN_SmoothL1=0.540,RPNAcc=0.965,RPNL1Loss=0.669,RCNNAcc=0.805,RCNNL1Loss=2.232\n",
            "[Epoch 0][Batch 43], Speed: 1.384 samples/sec, RPN_Conf=0.111,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.631,RCNN_SmoothL1=0.541,RPNAcc=0.966,RPNL1Loss=0.671,RCNNAcc=0.805,RCNNL1Loss=2.233\n",
            "[Epoch 0][Batch 44], Speed: 1.433 samples/sec, RPN_Conf=0.110,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.627,RCNN_SmoothL1=0.541,RPNAcc=0.966,RPNL1Loss=0.664,RCNNAcc=0.805,RCNNL1Loss=2.232\n",
            "[Epoch 0][Batch 45], Speed: 1.383 samples/sec, RPN_Conf=0.109,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.625,RCNN_SmoothL1=0.541,RPNAcc=0.966,RPNL1Loss=0.651,RCNNAcc=0.804,RCNNL1Loss=2.233\n",
            "[Epoch 0][Batch 46], Speed: 1.425 samples/sec, RPN_Conf=0.107,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.618,RCNN_SmoothL1=0.542,RPNAcc=0.966,RPNL1Loss=0.644,RCNNAcc=0.805,RCNNL1Loss=2.234\n",
            "[Epoch 0][Batch 47], Speed: 1.410 samples/sec, RPN_Conf=0.105,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.625,RCNN_SmoothL1=0.544,RPNAcc=0.967,RPNL1Loss=0.642,RCNNAcc=0.804,RCNNL1Loss=2.240\n",
            "[Epoch 0][Batch 48], Speed: 1.416 samples/sec, RPN_Conf=0.104,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.622,RCNN_SmoothL1=0.546,RPNAcc=0.968,RPNL1Loss=0.640,RCNNAcc=0.804,RCNNL1Loss=2.246\n",
            "[Epoch 0][Batch 49], Speed: 1.430 samples/sec, RPN_Conf=0.102,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.616,RCNN_SmoothL1=0.547,RPNAcc=0.968,RPNL1Loss=0.636,RCNNAcc=0.806,RCNNL1Loss=2.249\n",
            "[Epoch 0][Batch 50], Speed: 1.466 samples/sec, RPN_Conf=0.101,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.609,RCNN_SmoothL1=0.546,RPNAcc=0.969,RPNL1Loss=0.632,RCNNAcc=0.807,RCNNL1Loss=2.246\n",
            "[Epoch 0][Batch 51], Speed: 1.359 samples/sec, RPN_Conf=0.099,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.602,RCNN_SmoothL1=0.547,RPNAcc=0.969,RPNL1Loss=0.628,RCNNAcc=0.810,RCNNL1Loss=2.246\n",
            "[Epoch 0][Batch 52], Speed: 1.416 samples/sec, RPN_Conf=0.097,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.596,RCNN_SmoothL1=0.546,RPNAcc=0.970,RPNL1Loss=0.624,RCNNAcc=0.812,RCNNL1Loss=2.243\n",
            "[Epoch 0][Batch 53], Speed: 1.446 samples/sec, RPN_Conf=0.096,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.592,RCNN_SmoothL1=0.545,RPNAcc=0.970,RPNL1Loss=0.621,RCNNAcc=0.814,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 54], Speed: 1.406 samples/sec, RPN_Conf=0.095,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.584,RCNN_SmoothL1=0.546,RPNAcc=0.970,RPNL1Loss=0.618,RCNNAcc=0.817,RCNNL1Loss=2.239\n",
            "[Epoch 0][Batch 55], Speed: 1.412 samples/sec, RPN_Conf=0.094,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.579,RCNN_SmoothL1=0.545,RPNAcc=0.971,RPNL1Loss=0.615,RCNNAcc=0.819,RCNNL1Loss=2.235\n",
            "[Epoch 0][Batch 56], Speed: 1.411 samples/sec, RPN_Conf=0.092,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.571,RCNN_SmoothL1=0.545,RPNAcc=0.971,RPNL1Loss=0.612,RCNNAcc=0.821,RCNNL1Loss=2.233\n",
            "[Epoch 0][Batch 57], Speed: 1.389 samples/sec, RPN_Conf=0.091,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.565,RCNN_SmoothL1=0.545,RPNAcc=0.972,RPNL1Loss=0.609,RCNNAcc=0.823,RCNNL1Loss=2.235\n",
            "[Epoch 0][Batch 58], Speed: 1.580 samples/sec, RPN_Conf=0.090,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.560,RCNN_SmoothL1=0.546,RPNAcc=0.972,RPNL1Loss=0.608,RCNNAcc=0.825,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 59], Speed: 1.254 samples/sec, RPN_Conf=0.088,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.554,RCNN_SmoothL1=0.544,RPNAcc=0.972,RPNL1Loss=0.614,RCNNAcc=0.827,RCNNL1Loss=2.229\n",
            "[Epoch 0][Batch 60], Speed: 1.403 samples/sec, RPN_Conf=0.088,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.551,RCNN_SmoothL1=0.546,RPNAcc=0.972,RPNL1Loss=0.617,RCNNAcc=0.827,RCNNL1Loss=2.234\n",
            "[Epoch 0][Batch 61], Speed: 1.391 samples/sec, RPN_Conf=0.086,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.548,RCNN_SmoothL1=0.548,RPNAcc=0.973,RPNL1Loss=0.615,RCNNAcc=0.828,RCNNL1Loss=2.243\n",
            "[Epoch 0][Batch 62], Speed: 1.420 samples/sec, RPN_Conf=0.085,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.543,RCNN_SmoothL1=0.549,RPNAcc=0.973,RPNL1Loss=0.611,RCNNAcc=0.829,RCNNL1Loss=2.247\n",
            "[Epoch 0][Batch 63], Speed: 1.391 samples/sec, RPN_Conf=0.084,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.540,RCNN_SmoothL1=0.548,RPNAcc=0.974,RPNL1Loss=0.609,RCNNAcc=0.830,RCNNL1Loss=2.240\n",
            "[Epoch 0][Batch 64], Speed: 1.393 samples/sec, RPN_Conf=0.083,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.537,RCNN_SmoothL1=0.547,RPNAcc=0.974,RPNL1Loss=0.613,RCNNAcc=0.830,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 65], Speed: 1.423 samples/sec, RPN_Conf=0.083,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.535,RCNN_SmoothL1=0.547,RPNAcc=0.974,RPNL1Loss=0.609,RCNNAcc=0.830,RCNNL1Loss=2.236\n",
            "[Epoch 0][Batch 66], Speed: 1.400 samples/sec, RPN_Conf=0.082,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.534,RCNN_SmoothL1=0.547,RPNAcc=0.975,RPNL1Loss=0.606,RCNNAcc=0.829,RCNNL1Loss=2.233\n",
            "[Epoch 0][Batch 67], Speed: 1.388 samples/sec, RPN_Conf=0.081,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.531,RCNN_SmoothL1=0.546,RPNAcc=0.975,RPNL1Loss=0.605,RCNNAcc=0.829,RCNNL1Loss=2.230\n",
            "[Epoch 0][Batch 68], Speed: 1.449 samples/sec, RPN_Conf=0.080,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.530,RCNN_SmoothL1=0.547,RPNAcc=0.975,RPNL1Loss=0.604,RCNNAcc=0.829,RCNNL1Loss=2.231\n",
            "[Epoch 0][Batch 69], Speed: 1.421 samples/sec, RPN_Conf=0.079,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.530,RCNN_SmoothL1=0.547,RPNAcc=0.975,RPNL1Loss=0.609,RCNNAcc=0.829,RCNNL1Loss=2.230\n",
            "[Epoch 0][Batch 70], Speed: 1.416 samples/sec, RPN_Conf=0.078,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.527,RCNN_SmoothL1=0.547,RPNAcc=0.976,RPNL1Loss=0.612,RCNNAcc=0.830,RCNNL1Loss=2.232\n",
            "[Epoch 0][Batch 71], Speed: 1.408 samples/sec, RPN_Conf=0.078,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.525,RCNN_SmoothL1=0.546,RPNAcc=0.976,RPNL1Loss=0.610,RCNNAcc=0.830,RCNNL1Loss=2.227\n",
            "[Epoch 0][Batch 72], Speed: 1.465 samples/sec, RPN_Conf=0.077,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.522,RCNN_SmoothL1=0.546,RPNAcc=0.976,RPNL1Loss=0.606,RCNNAcc=0.830,RCNNL1Loss=2.227\n",
            "[Epoch 0][Batch 73], Speed: 1.404 samples/sec, RPN_Conf=0.076,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.521,RCNN_SmoothL1=0.546,RPNAcc=0.976,RPNL1Loss=0.602,RCNNAcc=0.831,RCNNL1Loss=2.224\n",
            "[Epoch 0][Batch 74], Speed: 1.341 samples/sec, RPN_Conf=0.076,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.518,RCNN_SmoothL1=0.546,RPNAcc=0.976,RPNL1Loss=0.599,RCNNAcc=0.832,RCNNL1Loss=2.224\n",
            "[Epoch 0][Batch 75], Speed: 1.403 samples/sec, RPN_Conf=0.076,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.516,RCNN_SmoothL1=0.546,RPNAcc=0.977,RPNL1Loss=0.598,RCNNAcc=0.832,RCNNL1Loss=2.223\n",
            "[Epoch 0][Batch 76], Speed: 1.440 samples/sec, RPN_Conf=0.075,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.514,RCNN_SmoothL1=0.546,RPNAcc=0.977,RPNL1Loss=0.594,RCNNAcc=0.832,RCNNL1Loss=2.224\n",
            "[Epoch 0][Batch 77], Speed: 1.541 samples/sec, RPN_Conf=0.074,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.512,RCNN_SmoothL1=0.546,RPNAcc=0.977,RPNL1Loss=0.590,RCNNAcc=0.832,RCNNL1Loss=2.224\n",
            "[Epoch 0][Batch 78], Speed: 1.260 samples/sec, RPN_Conf=0.074,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.511,RCNN_SmoothL1=0.546,RPNAcc=0.977,RPNL1Loss=0.588,RCNNAcc=0.832,RCNNL1Loss=2.224\n",
            "[Epoch 0][Batch 79], Speed: 1.428 samples/sec, RPN_Conf=0.073,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.508,RCNN_SmoothL1=0.547,RPNAcc=0.977,RPNL1Loss=0.587,RCNNAcc=0.833,RCNNL1Loss=2.225\n",
            "[Epoch 0][Batch 80], Speed: 1.307 samples/sec, RPN_Conf=0.073,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.506,RCNN_SmoothL1=0.546,RPNAcc=0.978,RPNL1Loss=0.585,RCNNAcc=0.833,RCNNL1Loss=2.222\n",
            "[Epoch 0][Batch 81], Speed: 1.473 samples/sec, RPN_Conf=0.072,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.501,RCNN_SmoothL1=0.545,RPNAcc=0.978,RPNL1Loss=0.583,RCNNAcc=0.834,RCNNL1Loss=2.217\n",
            "[Epoch 0][Batch 82], Speed: 1.435 samples/sec, RPN_Conf=0.071,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.500,RCNN_SmoothL1=0.544,RPNAcc=0.978,RPNL1Loss=0.581,RCNNAcc=0.834,RCNNL1Loss=2.213\n",
            "[Epoch 0][Batch 83], Speed: 1.370 samples/sec, RPN_Conf=0.071,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.497,RCNN_SmoothL1=0.543,RPNAcc=0.978,RPNL1Loss=0.578,RCNNAcc=0.835,RCNNL1Loss=2.208\n",
            "[Epoch 0][Batch 84], Speed: 1.418 samples/sec, RPN_Conf=0.070,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.497,RCNN_SmoothL1=0.543,RPNAcc=0.978,RPNL1Loss=0.576,RCNNAcc=0.835,RCNNL1Loss=2.207\n",
            "[Epoch 0][Batch 85], Speed: 1.346 samples/sec, RPN_Conf=0.070,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.494,RCNN_SmoothL1=0.541,RPNAcc=0.979,RPNL1Loss=0.574,RCNNAcc=0.836,RCNNL1Loss=2.200\n",
            "[Epoch 0][Batch 86], Speed: 1.389 samples/sec, RPN_Conf=0.069,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.491,RCNN_SmoothL1=0.541,RPNAcc=0.979,RPNL1Loss=0.574,RCNNAcc=0.836,RCNNL1Loss=2.198\n",
            "[Epoch 0][Batch 87], Speed: 1.411 samples/sec, RPN_Conf=0.068,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.489,RCNN_SmoothL1=0.540,RPNAcc=0.979,RPNL1Loss=0.572,RCNNAcc=0.836,RCNNL1Loss=2.195\n",
            "[Epoch 0][Batch 88], Speed: 1.356 samples/sec, RPN_Conf=0.068,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.487,RCNN_SmoothL1=0.540,RPNAcc=0.979,RPNL1Loss=0.569,RCNNAcc=0.837,RCNNL1Loss=2.193\n",
            "[Epoch 0][Batch 89], Speed: 1.374 samples/sec, RPN_Conf=0.067,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.484,RCNN_SmoothL1=0.538,RPNAcc=0.979,RPNL1Loss=0.569,RCNNAcc=0.838,RCNNL1Loss=2.187\n",
            "[Epoch 0][Batch 90], Speed: 1.419 samples/sec, RPN_Conf=0.067,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.483,RCNN_SmoothL1=0.538,RPNAcc=0.980,RPNL1Loss=0.575,RCNNAcc=0.838,RCNNL1Loss=2.187\n",
            "[Epoch 0][Batch 91], Speed: 1.505 samples/sec, RPN_Conf=0.066,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.482,RCNN_SmoothL1=0.537,RPNAcc=0.980,RPNL1Loss=0.575,RCNNAcc=0.838,RCNNL1Loss=2.181\n",
            "[Epoch 0][Batch 92], Speed: 1.297 samples/sec, RPN_Conf=0.066,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.479,RCNN_SmoothL1=0.538,RPNAcc=0.980,RPNL1Loss=0.573,RCNNAcc=0.839,RCNNL1Loss=2.184\n",
            "[Epoch 0][Batch 93], Speed: 1.308 samples/sec, RPN_Conf=0.065,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.477,RCNN_SmoothL1=0.539,RPNAcc=0.980,RPNL1Loss=0.572,RCNNAcc=0.840,RCNNL1Loss=2.187\n",
            "[Epoch 0][Batch 94], Speed: 1.389 samples/sec, RPN_Conf=0.064,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.476,RCNN_SmoothL1=0.537,RPNAcc=0.980,RPNL1Loss=0.569,RCNNAcc=0.840,RCNNL1Loss=2.180\n",
            "[Epoch 0][Batch 95], Speed: 1.328 samples/sec, RPN_Conf=0.064,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.472,RCNN_SmoothL1=0.537,RPNAcc=0.980,RPNL1Loss=0.566,RCNNAcc=0.841,RCNNL1Loss=2.178\n",
            "[Epoch 0][Batch 96], Speed: 1.401 samples/sec, RPN_Conf=0.063,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.470,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.565,RCNNAcc=0.842,RCNNL1Loss=2.175\n",
            "[Epoch 0][Batch 97], Speed: 1.334 samples/sec, RPN_Conf=0.063,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.468,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.563,RCNNAcc=0.842,RCNNL1Loss=2.176\n",
            "[Epoch 0][Batch 98], Speed: 1.372 samples/sec, RPN_Conf=0.062,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.466,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.563,RCNNAcc=0.843,RCNNL1Loss=2.174\n",
            "[Epoch 0][Batch 99], Speed: 1.288 samples/sec, RPN_Conf=0.062,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.464,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.561,RCNNAcc=0.844,RCNNL1Loss=2.173\n",
            "[Epoch 0][Batch 100], Speed: 1.444 samples/sec, RPN_Conf=0.061,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.462,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.560,RCNNAcc=0.844,RCNNL1Loss=2.172\n",
            "[Epoch 0][Batch 101], Speed: 1.357 samples/sec, RPN_Conf=0.061,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.460,RCNN_SmoothL1=0.536,RPNAcc=0.981,RPNL1Loss=0.559,RCNNAcc=0.844,RCNNL1Loss=2.172\n",
            "[Epoch 0][Batch 102], Speed: 1.361 samples/sec, RPN_Conf=0.061,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.458,RCNN_SmoothL1=0.535,RPNAcc=0.981,RPNL1Loss=0.557,RCNNAcc=0.845,RCNNL1Loss=2.171\n",
            "[Epoch 0][Batch 103], Speed: 1.339 samples/sec, RPN_Conf=0.060,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.455,RCNN_SmoothL1=0.536,RPNAcc=0.982,RPNL1Loss=0.555,RCNNAcc=0.846,RCNNL1Loss=2.173\n",
            "[Epoch 0][Batch 104], Speed: 1.378 samples/sec, RPN_Conf=0.060,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.455,RCNN_SmoothL1=0.536,RPNAcc=0.982,RPNL1Loss=0.559,RCNNAcc=0.845,RCNNL1Loss=2.172\n",
            "[Epoch 0][Batch 105], Speed: 1.353 samples/sec, RPN_Conf=0.060,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.454,RCNN_SmoothL1=0.535,RPNAcc=0.982,RPNL1Loss=0.557,RCNNAcc=0.846,RCNNL1Loss=2.170\n",
            "[Epoch 0][Batch 106], Speed: 1.374 samples/sec, RPN_Conf=0.059,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.453,RCNN_SmoothL1=0.535,RPNAcc=0.982,RPNL1Loss=0.555,RCNNAcc=0.845,RCNNL1Loss=2.168\n",
            "[Epoch 0][Batch 107], Speed: 1.363 samples/sec, RPN_Conf=0.059,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.452,RCNN_SmoothL1=0.535,RPNAcc=0.982,RPNL1Loss=0.554,RCNNAcc=0.845,RCNNL1Loss=2.169\n",
            "[Epoch 0][Batch 108], Speed: 1.389 samples/sec, RPN_Conf=0.059,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.450,RCNN_SmoothL1=0.536,RPNAcc=0.982,RPNL1Loss=0.552,RCNNAcc=0.846,RCNNL1Loss=2.171\n",
            "[Epoch 0][Batch 109], Speed: 1.339 samples/sec, RPN_Conf=0.058,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.450,RCNN_SmoothL1=0.535,RPNAcc=0.982,RPNL1Loss=0.551,RCNNAcc=0.846,RCNNL1Loss=2.168\n",
            "[Epoch 0][Batch 110], Speed: 1.362 samples/sec, RPN_Conf=0.058,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.447,RCNN_SmoothL1=0.535,RPNAcc=0.982,RPNL1Loss=0.549,RCNNAcc=0.847,RCNNL1Loss=2.165\n",
            "[Epoch 0][Batch 111], Speed: 1.353 samples/sec, RPN_Conf=0.057,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.445,RCNN_SmoothL1=0.534,RPNAcc=0.982,RPNL1Loss=0.547,RCNNAcc=0.847,RCNNL1Loss=2.163\n",
            "[Epoch 0][Batch 112], Speed: 1.391 samples/sec, RPN_Conf=0.057,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.445,RCNN_SmoothL1=0.534,RPNAcc=0.983,RPNL1Loss=0.546,RCNNAcc=0.847,RCNNL1Loss=2.161\n",
            "[Epoch 0][Batch 113], Speed: 1.365 samples/sec, RPN_Conf=0.057,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.443,RCNN_SmoothL1=0.533,RPNAcc=0.983,RPNL1Loss=0.545,RCNNAcc=0.848,RCNNL1Loss=2.158\n",
            "[Epoch 0][Batch 114], Speed: 1.413 samples/sec, RPN_Conf=0.056,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.442,RCNN_SmoothL1=0.532,RPNAcc=0.983,RPNL1Loss=0.543,RCNNAcc=0.848,RCNNL1Loss=2.155\n",
            "[Epoch 0][Batch 115], Speed: 1.364 samples/sec, RPN_Conf=0.056,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.440,RCNN_SmoothL1=0.532,RPNAcc=0.983,RPNL1Loss=0.541,RCNNAcc=0.849,RCNNL1Loss=2.154\n",
            "[Epoch 0][Batch 116], Speed: 1.368 samples/sec, RPN_Conf=0.056,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.439,RCNN_SmoothL1=0.531,RPNAcc=0.983,RPNL1Loss=0.540,RCNNAcc=0.850,RCNNL1Loss=2.149\n",
            "[Epoch 0][Batch 117], Speed: 1.350 samples/sec, RPN_Conf=0.055,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.437,RCNN_SmoothL1=0.530,RPNAcc=0.983,RPNL1Loss=0.539,RCNNAcc=0.850,RCNNL1Loss=2.145\n",
            "[Epoch 0][Batch 118], Speed: 1.377 samples/sec, RPN_Conf=0.055,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.438,RCNN_SmoothL1=0.530,RPNAcc=0.983,RPNL1Loss=0.536,RCNNAcc=0.850,RCNNL1Loss=2.145\n",
            "[Epoch 0][Batch 119], Speed: 1.382 samples/sec, RPN_Conf=0.054,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.437,RCNN_SmoothL1=0.529,RPNAcc=0.983,RPNL1Loss=0.535,RCNNAcc=0.850,RCNNL1Loss=2.141\n",
            "[Epoch 0][Batch 120], Speed: 1.399 samples/sec, RPN_Conf=0.054,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.434,RCNN_SmoothL1=0.528,RPNAcc=0.983,RPNL1Loss=0.532,RCNNAcc=0.851,RCNNL1Loss=2.135\n",
            "[Epoch 0][Batch 121], Speed: 1.363 samples/sec, RPN_Conf=0.054,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.433,RCNN_SmoothL1=0.527,RPNAcc=0.984,RPNL1Loss=0.530,RCNNAcc=0.851,RCNNL1Loss=2.131\n",
            "[Epoch 0][Batch 122], Speed: 1.390 samples/sec, RPN_Conf=0.053,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.434,RCNN_SmoothL1=0.526,RPNAcc=0.984,RPNL1Loss=0.527,RCNNAcc=0.851,RCNNL1Loss=2.129\n",
            "[Epoch 0][Batch 123], Speed: 1.410 samples/sec, RPN_Conf=0.053,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.432,RCNN_SmoothL1=0.526,RPNAcc=0.984,RPNL1Loss=0.526,RCNNAcc=0.851,RCNNL1Loss=2.126\n",
            "[Epoch 0][Batch 124], Speed: 1.341 samples/sec, RPN_Conf=0.053,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.431,RCNN_SmoothL1=0.525,RPNAcc=0.984,RPNL1Loss=0.524,RCNNAcc=0.852,RCNNL1Loss=2.124\n",
            "[Epoch 0][Batch 125], Speed: 1.366 samples/sec, RPN_Conf=0.052,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.429,RCNN_SmoothL1=0.524,RPNAcc=0.984,RPNL1Loss=0.522,RCNNAcc=0.852,RCNNL1Loss=2.120\n",
            "[Epoch 0][Batch 126], Speed: 1.377 samples/sec, RPN_Conf=0.052,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.429,RCNN_SmoothL1=0.524,RPNAcc=0.984,RPNL1Loss=0.520,RCNNAcc=0.852,RCNNL1Loss=2.119\n",
            "[Epoch 0][Batch 127], Speed: 1.380 samples/sec, RPN_Conf=0.052,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.427,RCNN_SmoothL1=0.523,RPNAcc=0.984,RPNL1Loss=0.518,RCNNAcc=0.853,RCNNL1Loss=2.115\n",
            "[Epoch 0][Batch 128], Speed: 1.370 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.428,RCNN_SmoothL1=0.522,RPNAcc=0.984,RPNL1Loss=0.516,RCNNAcc=0.853,RCNNL1Loss=2.111\n",
            "[Epoch 0][Batch 129], Speed: 1.377 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.426,RCNN_SmoothL1=0.522,RPNAcc=0.984,RPNL1Loss=0.514,RCNNAcc=0.853,RCNNL1Loss=2.109\n",
            "[Epoch 0][Batch 130], Speed: 1.343 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.425,RCNN_SmoothL1=0.521,RPNAcc=0.985,RPNL1Loss=0.513,RCNNAcc=0.854,RCNNL1Loss=2.107\n",
            "[Epoch 0][Batch 131], Speed: 1.375 samples/sec, RPN_Conf=0.050,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.424,RCNN_SmoothL1=0.521,RPNAcc=0.985,RPNL1Loss=0.511,RCNNAcc=0.854,RCNNL1Loss=2.106\n",
            "[Epoch 0][Batch 132], Speed: 1.373 samples/sec, RPN_Conf=0.050,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.423,RCNN_SmoothL1=0.521,RPNAcc=0.985,RPNL1Loss=0.510,RCNNAcc=0.854,RCNNL1Loss=2.107\n",
            "[Epoch 0][Batch 133], Speed: 1.356 samples/sec, RPN_Conf=0.050,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.421,RCNN_SmoothL1=0.521,RPNAcc=0.985,RPNL1Loss=0.508,RCNNAcc=0.855,RCNNL1Loss=2.105\n",
            "[Epoch 0][Batch 134], Speed: 1.377 samples/sec, RPN_Conf=0.050,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.420,RCNN_SmoothL1=0.520,RPNAcc=0.985,RPNL1Loss=0.506,RCNNAcc=0.855,RCNNL1Loss=2.102\n",
            "[Epoch 0][Batch 135], Speed: 1.368 samples/sec, RPN_Conf=0.049,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.418,RCNN_SmoothL1=0.520,RPNAcc=0.985,RPNL1Loss=0.505,RCNNAcc=0.856,RCNNL1Loss=2.100\n",
            "[Epoch 0][Batch 136], Speed: 1.355 samples/sec, RPN_Conf=0.049,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.416,RCNN_SmoothL1=0.519,RPNAcc=0.985,RPNL1Loss=0.504,RCNNAcc=0.857,RCNNL1Loss=2.095\n",
            "[Epoch 0][Batch 137], Speed: 1.352 samples/sec, RPN_Conf=0.049,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.414,RCNN_SmoothL1=0.517,RPNAcc=0.985,RPNL1Loss=0.502,RCNNAcc=0.857,RCNNL1Loss=2.090\n",
            "[Epoch 0][Batch 138], Speed: 1.404 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.413,RCNN_SmoothL1=0.517,RPNAcc=0.985,RPNL1Loss=0.503,RCNNAcc=0.858,RCNNL1Loss=2.089\n",
            "[Epoch 0][Batch 139], Speed: 1.348 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.412,RCNN_SmoothL1=0.516,RPNAcc=0.985,RPNL1Loss=0.501,RCNNAcc=0.858,RCNNL1Loss=2.085\n",
            "[Epoch 0][Batch 140], Speed: 1.371 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.410,RCNN_SmoothL1=0.515,RPNAcc=0.985,RPNL1Loss=0.500,RCNNAcc=0.858,RCNNL1Loss=2.082\n",
            "[Epoch 0][Batch 141], Speed: 1.391 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.410,RCNN_SmoothL1=0.515,RPNAcc=0.986,RPNL1Loss=0.500,RCNNAcc=0.858,RCNNL1Loss=2.081\n",
            "[Epoch 0][Batch 142], Speed: 1.357 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.409,RCNN_SmoothL1=0.515,RPNAcc=0.986,RPNL1Loss=0.498,RCNNAcc=0.858,RCNNL1Loss=2.080\n",
            "[Epoch 0][Batch 143], Speed: 1.367 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.408,RCNN_SmoothL1=0.514,RPNAcc=0.986,RPNL1Loss=0.498,RCNNAcc=0.859,RCNNL1Loss=2.075\n",
            "[Epoch 0][Batch 144], Speed: 1.378 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.406,RCNN_SmoothL1=0.513,RPNAcc=0.986,RPNL1Loss=0.497,RCNNAcc=0.859,RCNNL1Loss=2.073\n",
            "[Epoch 0][Batch 145], Speed: 1.377 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.404,RCNN_SmoothL1=0.512,RPNAcc=0.986,RPNL1Loss=0.495,RCNNAcc=0.860,RCNNL1Loss=2.069\n",
            "[Epoch 0][Batch 146], Speed: 1.377 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.027,RCNN_CrossEntropy=0.403,RCNN_SmoothL1=0.511,RPNAcc=0.986,RPNL1Loss=0.494,RCNNAcc=0.860,RCNNL1Loss=2.064\n",
            "[Epoch 0][Batch 147], Speed: 1.357 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.403,RCNN_SmoothL1=0.510,RPNAcc=0.986,RPNL1Loss=0.493,RCNNAcc=0.860,RCNNL1Loss=2.061\n",
            "[Epoch 0][Batch 148], Speed: 1.388 samples/sec, RPN_Conf=0.046,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.400,RCNN_SmoothL1=0.509,RPNAcc=0.986,RPNL1Loss=0.492,RCNNAcc=0.861,RCNNL1Loss=2.055\n",
            "[Epoch 0][Batch 149], Speed: 1.388 samples/sec, RPN_Conf=0.046,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.399,RCNN_SmoothL1=0.507,RPNAcc=0.986,RPNL1Loss=0.490,RCNNAcc=0.862,RCNNL1Loss=2.048\n",
            "[Epoch 0][Batch 150], Speed: 1.338 samples/sec, RPN_Conf=0.046,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.397,RCNN_SmoothL1=0.506,RPNAcc=0.986,RPNL1Loss=0.488,RCNNAcc=0.862,RCNNL1Loss=2.042\n",
            "[Epoch 0][Batch 151], Speed: 1.419 samples/sec, RPN_Conf=0.046,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.396,RCNN_SmoothL1=0.505,RPNAcc=0.986,RPNL1Loss=0.487,RCNNAcc=0.862,RCNNL1Loss=2.039\n",
            "[Epoch 0][Batch 152], Speed: 1.330 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.395,RCNN_SmoothL1=0.504,RPNAcc=0.986,RPNL1Loss=0.487,RCNNAcc=0.863,RCNNL1Loss=2.035\n",
            "[Epoch 0][Batch 153], Speed: 1.348 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.393,RCNN_SmoothL1=0.503,RPNAcc=0.986,RPNL1Loss=0.486,RCNNAcc=0.863,RCNNL1Loss=2.030\n",
            "[Epoch 0][Batch 154], Speed: 1.362 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.391,RCNN_SmoothL1=0.502,RPNAcc=0.986,RPNL1Loss=0.484,RCNNAcc=0.864,RCNNL1Loss=2.025\n",
            "[Epoch 0][Batch 155], Speed: 1.393 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.390,RCNN_SmoothL1=0.501,RPNAcc=0.986,RPNL1Loss=0.485,RCNNAcc=0.865,RCNNL1Loss=2.022\n",
            "[Epoch 0][Batch 156], Speed: 1.253 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.388,RCNN_SmoothL1=0.500,RPNAcc=0.986,RPNL1Loss=0.484,RCNNAcc=0.865,RCNNL1Loss=2.019\n",
            "[Epoch 0][Batch 157], Speed: 1.427 samples/sec, RPN_Conf=0.044,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.386,RCNN_SmoothL1=0.499,RPNAcc=0.986,RPNL1Loss=0.483,RCNNAcc=0.866,RCNNL1Loss=2.012\n",
            "[Epoch 0][Batch 158], Speed: 1.411 samples/sec, RPN_Conf=0.044,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.385,RCNN_SmoothL1=0.497,RPNAcc=0.986,RPNL1Loss=0.483,RCNNAcc=0.866,RCNNL1Loss=2.006\n",
            "[Epoch 0][Batch 159], Speed: 1.346 samples/sec, RPN_Conf=0.044,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.384,RCNN_SmoothL1=0.496,RPNAcc=0.987,RPNL1Loss=0.481,RCNNAcc=0.867,RCNNL1Loss=2.000\n",
            "[Epoch 0][Batch 160], Speed: 1.346 samples/sec, RPN_Conf=0.044,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.382,RCNN_SmoothL1=0.495,RPNAcc=0.987,RPNL1Loss=0.480,RCNNAcc=0.867,RCNNL1Loss=1.995\n",
            "[Epoch 0][Batch 161], Speed: 1.363 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.381,RCNN_SmoothL1=0.494,RPNAcc=0.987,RPNL1Loss=0.479,RCNNAcc=0.868,RCNNL1Loss=1.992\n",
            "[Epoch 0][Batch 162], Speed: 1.361 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.026,RCNN_CrossEntropy=0.379,RCNN_SmoothL1=0.492,RPNAcc=0.987,RPNL1Loss=0.477,RCNNAcc=0.868,RCNNL1Loss=1.986\n",
            "[Epoch 0][Batch 163], Speed: 1.350 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.378,RCNN_SmoothL1=0.491,RPNAcc=0.987,RPNL1Loss=0.476,RCNNAcc=0.869,RCNNL1Loss=1.980\n",
            "[Epoch 0][Batch 164], Speed: 1.347 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.377,RCNN_SmoothL1=0.490,RPNAcc=0.987,RPNL1Loss=0.475,RCNNAcc=0.869,RCNNL1Loss=1.975\n",
            "[Epoch 0][Batch 165], Speed: 1.415 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.375,RCNN_SmoothL1=0.489,RPNAcc=0.987,RPNL1Loss=0.473,RCNNAcc=0.870,RCNNL1Loss=1.971\n",
            "[Epoch 0][Batch 166], Speed: 1.328 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.374,RCNN_SmoothL1=0.488,RPNAcc=0.987,RPNL1Loss=0.472,RCNNAcc=0.870,RCNNL1Loss=1.967\n",
            "[Epoch 0][Batch 167], Speed: 1.342 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.373,RCNN_SmoothL1=0.487,RPNAcc=0.987,RPNL1Loss=0.471,RCNNAcc=0.870,RCNNL1Loss=1.964\n",
            "[Epoch 0][Batch 168], Speed: 1.374 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.372,RCNN_SmoothL1=0.486,RPNAcc=0.987,RPNL1Loss=0.469,RCNNAcc=0.871,RCNNL1Loss=1.960\n",
            "[Epoch 0][Batch 169], Speed: 1.364 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.370,RCNN_SmoothL1=0.485,RPNAcc=0.987,RPNL1Loss=0.469,RCNNAcc=0.871,RCNNL1Loss=1.954\n",
            "[Epoch 0][Batch 170], Speed: 1.421 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.369,RCNN_SmoothL1=0.484,RPNAcc=0.987,RPNL1Loss=0.468,RCNNAcc=0.872,RCNNL1Loss=1.950\n",
            "[Epoch 0][Batch 171], Speed: 1.275 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.368,RCNN_SmoothL1=0.482,RPNAcc=0.987,RPNL1Loss=0.472,RCNNAcc=0.872,RCNNL1Loss=1.945\n",
            "[Epoch 0][Batch 172], Speed: 1.416 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.367,RCNN_SmoothL1=0.481,RPNAcc=0.987,RPNL1Loss=0.470,RCNNAcc=0.872,RCNNL1Loss=1.941\n",
            "[Epoch 0][Batch 173], Speed: 1.400 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.366,RCNN_SmoothL1=0.480,RPNAcc=0.987,RPNL1Loss=0.468,RCNNAcc=0.873,RCNNL1Loss=1.936\n",
            "[Epoch 0][Batch 174], Speed: 1.303 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.364,RCNN_SmoothL1=0.479,RPNAcc=0.987,RPNL1Loss=0.467,RCNNAcc=0.873,RCNNL1Loss=1.931\n",
            "[Epoch 0][Batch 175], Speed: 1.470 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.363,RCNN_SmoothL1=0.478,RPNAcc=0.987,RPNL1Loss=0.470,RCNNAcc=0.874,RCNNL1Loss=1.927\n",
            "[Epoch 0][Batch 176], Speed: 1.318 samples/sec, RPN_Conf=0.041,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.362,RCNN_SmoothL1=0.477,RPNAcc=0.988,RPNL1Loss=0.469,RCNNAcc=0.874,RCNNL1Loss=1.923\n",
            "[Epoch 0][Batch 177], Speed: 1.354 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.360,RCNN_SmoothL1=0.476,RPNAcc=0.988,RPNL1Loss=0.469,RCNNAcc=0.874,RCNNL1Loss=1.920\n",
            "[Epoch 0][Batch 178], Speed: 1.364 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.360,RCNN_SmoothL1=0.476,RPNAcc=0.988,RPNL1Loss=0.469,RCNNAcc=0.875,RCNNL1Loss=1.919\n",
            "[Epoch 0][Batch 179], Speed: 1.335 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.359,RCNN_SmoothL1=0.476,RPNAcc=0.988,RPNL1Loss=0.467,RCNNAcc=0.875,RCNNL1Loss=1.918\n",
            "[Epoch 0][Batch 180], Speed: 1.378 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.357,RCNN_SmoothL1=0.475,RPNAcc=0.988,RPNL1Loss=0.469,RCNNAcc=0.875,RCNNL1Loss=1.914\n",
            "[Epoch 0][Batch 181], Speed: 1.357 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.356,RCNN_SmoothL1=0.474,RPNAcc=0.988,RPNL1Loss=0.468,RCNNAcc=0.876,RCNNL1Loss=1.910\n",
            "[Epoch 0][Batch 182], Speed: 1.336 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.355,RCNN_SmoothL1=0.473,RPNAcc=0.988,RPNL1Loss=0.467,RCNNAcc=0.876,RCNNL1Loss=1.906\n",
            "[Epoch 0][Batch 183], Speed: 1.364 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.354,RCNN_SmoothL1=0.472,RPNAcc=0.988,RPNL1Loss=0.465,RCNNAcc=0.876,RCNNL1Loss=1.901\n",
            "[Epoch 0][Batch 184], Speed: 1.338 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.353,RCNN_SmoothL1=0.471,RPNAcc=0.988,RPNL1Loss=0.463,RCNNAcc=0.877,RCNNL1Loss=1.897\n",
            "[Epoch 0][Batch 185], Speed: 1.372 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.353,RCNN_SmoothL1=0.470,RPNAcc=0.988,RPNL1Loss=0.462,RCNNAcc=0.877,RCNNL1Loss=1.893\n",
            "[Epoch 0][Batch 186], Speed: 1.367 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.353,RCNN_SmoothL1=0.469,RPNAcc=0.988,RPNL1Loss=0.461,RCNNAcc=0.877,RCNNL1Loss=1.888\n",
            "[Epoch 0][Batch 187], Speed: 1.348 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.352,RCNN_SmoothL1=0.468,RPNAcc=0.988,RPNL1Loss=0.460,RCNNAcc=0.877,RCNNL1Loss=1.884\n",
            "[Epoch 0][Batch 188], Speed: 1.364 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.025,RCNN_CrossEntropy=0.350,RCNN_SmoothL1=0.466,RPNAcc=0.988,RPNL1Loss=0.459,RCNNAcc=0.878,RCNNL1Loss=1.879\n",
            "[Epoch 0][Batch 189], Speed: 1.365 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.350,RCNN_SmoothL1=0.465,RPNAcc=0.988,RPNL1Loss=0.458,RCNNAcc=0.878,RCNNL1Loss=1.875\n",
            "[Epoch 0][Batch 190], Speed: 1.359 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.349,RCNN_SmoothL1=0.464,RPNAcc=0.988,RPNL1Loss=0.457,RCNNAcc=0.878,RCNNL1Loss=1.869\n",
            "[Epoch 0][Batch 191], Speed: 1.351 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.348,RCNN_SmoothL1=0.463,RPNAcc=0.988,RPNL1Loss=0.456,RCNNAcc=0.879,RCNNL1Loss=1.864\n",
            "[Epoch 0][Batch 192], Speed: 1.385 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.347,RCNN_SmoothL1=0.462,RPNAcc=0.988,RPNL1Loss=0.455,RCNNAcc=0.879,RCNNL1Loss=1.860\n",
            "[Epoch 0][Batch 193], Speed: 1.350 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.346,RCNN_SmoothL1=0.460,RPNAcc=0.988,RPNL1Loss=0.454,RCNNAcc=0.879,RCNNL1Loss=1.855\n",
            "[Epoch 0][Batch 194], Speed: 1.386 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.344,RCNN_SmoothL1=0.459,RPNAcc=0.988,RPNL1Loss=0.456,RCNNAcc=0.880,RCNNL1Loss=1.848\n",
            "[Epoch 0][Batch 195], Speed: 1.386 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.344,RCNN_SmoothL1=0.458,RPNAcc=0.988,RPNL1Loss=0.456,RCNNAcc=0.880,RCNNL1Loss=1.844\n",
            "[Epoch 0][Batch 196], Speed: 1.403 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.343,RCNN_SmoothL1=0.457,RPNAcc=0.989,RPNL1Loss=0.454,RCNNAcc=0.880,RCNNL1Loss=1.839\n",
            "[Epoch 0][Batch 197], Speed: 1.332 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.341,RCNN_SmoothL1=0.455,RPNAcc=0.989,RPNL1Loss=0.454,RCNNAcc=0.881,RCNNL1Loss=1.834\n",
            "[Epoch 0][Batch 198], Speed: 1.374 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.341,RCNN_SmoothL1=0.454,RPNAcc=0.989,RPNL1Loss=0.453,RCNNAcc=0.881,RCNNL1Loss=1.829\n",
            "[Epoch 0][Batch 199], Speed: 1.379 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.340,RCNN_SmoothL1=0.453,RPNAcc=0.989,RPNL1Loss=0.452,RCNNAcc=0.881,RCNNL1Loss=1.826\n",
            "[Epoch 0][Batch 200], Speed: 1.502 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.340,RCNN_SmoothL1=0.452,RPNAcc=0.989,RPNL1Loss=0.451,RCNNAcc=0.881,RCNNL1Loss=1.822\n",
            "[Epoch 0][Batch 201], Speed: 1.217 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.341,RCNN_SmoothL1=0.451,RPNAcc=0.989,RPNL1Loss=0.451,RCNNAcc=0.881,RCNNL1Loss=1.818\n",
            "[Epoch 0][Batch 202], Speed: 1.362 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.340,RCNN_SmoothL1=0.450,RPNAcc=0.989,RPNL1Loss=0.450,RCNNAcc=0.882,RCNNL1Loss=1.814\n",
            "[Epoch 0][Batch 203], Speed: 1.379 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.339,RCNN_SmoothL1=0.450,RPNAcc=0.989,RPNL1Loss=0.450,RCNNAcc=0.882,RCNNL1Loss=1.811\n",
            "[Epoch 0][Batch 204], Speed: 1.357 samples/sec, RPN_Conf=0.037,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.338,RCNN_SmoothL1=0.449,RPNAcc=0.989,RPNL1Loss=0.449,RCNNAcc=0.882,RCNNL1Loss=1.808\n",
            "[Epoch 0][Batch 205], Speed: 1.341 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.338,RCNN_SmoothL1=0.448,RPNAcc=0.989,RPNL1Loss=0.449,RCNNAcc=0.882,RCNNL1Loss=1.804\n",
            "[Epoch 0][Batch 206], Speed: 1.365 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.337,RCNN_SmoothL1=0.447,RPNAcc=0.989,RPNL1Loss=0.447,RCNNAcc=0.882,RCNNL1Loss=1.801\n",
            "[Epoch 0][Batch 207], Speed: 1.376 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.336,RCNN_SmoothL1=0.446,RPNAcc=0.989,RPNL1Loss=0.446,RCNNAcc=0.883,RCNNL1Loss=1.797\n",
            "[Epoch 0][Batch 208], Speed: 1.340 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.335,RCNN_SmoothL1=0.445,RPNAcc=0.989,RPNL1Loss=0.445,RCNNAcc=0.883,RCNNL1Loss=1.794\n",
            "[Epoch 0][Batch 209], Speed: 1.213 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.335,RCNN_SmoothL1=0.445,RPNAcc=0.989,RPNL1Loss=0.444,RCNNAcc=0.883,RCNNL1Loss=1.790\n",
            "[Epoch 0][Batch 210], Speed: 1.524 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.334,RCNN_SmoothL1=0.444,RPNAcc=0.989,RPNL1Loss=0.442,RCNNAcc=0.883,RCNNL1Loss=1.788\n",
            "[Epoch 0][Batch 211], Speed: 1.328 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.334,RCNN_SmoothL1=0.443,RPNAcc=0.989,RPNL1Loss=0.442,RCNNAcc=0.883,RCNNL1Loss=1.783\n",
            "[Epoch 0][Batch 212], Speed: 1.388 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.333,RCNN_SmoothL1=0.442,RPNAcc=0.989,RPNL1Loss=0.442,RCNNAcc=0.884,RCNNL1Loss=1.779\n",
            "[Epoch 0][Batch 213], Speed: 1.331 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.332,RCNN_SmoothL1=0.441,RPNAcc=0.989,RPNL1Loss=0.442,RCNNAcc=0.884,RCNNL1Loss=1.775\n",
            "[Epoch 0][Batch 214], Speed: 1.382 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.331,RCNN_SmoothL1=0.440,RPNAcc=0.989,RPNL1Loss=0.442,RCNNAcc=0.884,RCNNL1Loss=1.770\n",
            "[Epoch 0][Batch 215], Speed: 1.339 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.331,RCNN_SmoothL1=0.439,RPNAcc=0.989,RPNL1Loss=0.441,RCNNAcc=0.884,RCNNL1Loss=1.766\n",
            "[Epoch 0][Batch 216], Speed: 1.386 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.331,RCNN_SmoothL1=0.438,RPNAcc=0.989,RPNL1Loss=0.441,RCNNAcc=0.884,RCNNL1Loss=1.763\n",
            "[Epoch 0][Batch 217], Speed: 1.367 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.330,RCNN_SmoothL1=0.437,RPNAcc=0.989,RPNL1Loss=0.441,RCNNAcc=0.884,RCNNL1Loss=1.758\n",
            "[Epoch 0][Batch 218], Speed: 1.350 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.329,RCNN_SmoothL1=0.436,RPNAcc=0.989,RPNL1Loss=0.441,RCNNAcc=0.885,RCNNL1Loss=1.754\n",
            "[Epoch 0][Batch 219], Speed: 1.349 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.328,RCNN_SmoothL1=0.435,RPNAcc=0.989,RPNL1Loss=0.440,RCNNAcc=0.885,RCNNL1Loss=1.750\n",
            "[Epoch 0][Batch 220], Speed: 1.364 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.328,RCNN_SmoothL1=0.434,RPNAcc=0.989,RPNL1Loss=0.439,RCNNAcc=0.885,RCNNL1Loss=1.747\n",
            "[Epoch 0][Batch 221], Speed: 1.318 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.327,RCNN_SmoothL1=0.433,RPNAcc=0.989,RPNL1Loss=0.439,RCNNAcc=0.885,RCNNL1Loss=1.743\n",
            "[Epoch 0][Batch 222], Speed: 1.321 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.326,RCNN_SmoothL1=0.432,RPNAcc=0.989,RPNL1Loss=0.438,RCNNAcc=0.885,RCNNL1Loss=1.737\n",
            "[Epoch 0][Batch 223], Speed: 1.425 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.329,RCNN_SmoothL1=0.431,RPNAcc=0.989,RPNL1Loss=0.437,RCNNAcc=0.885,RCNNL1Loss=1.735\n",
            "[Epoch 0][Batch 224], Speed: 1.334 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.328,RCNN_SmoothL1=0.430,RPNAcc=0.989,RPNL1Loss=0.436,RCNNAcc=0.885,RCNNL1Loss=1.731\n",
            "[Epoch 0][Batch 225], Speed: 1.389 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.329,RCNN_SmoothL1=0.429,RPNAcc=0.989,RPNL1Loss=0.435,RCNNAcc=0.885,RCNNL1Loss=1.728\n",
            "[Epoch 0][Batch 226], Speed: 1.364 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.024,RCNN_CrossEntropy=0.328,RCNN_SmoothL1=0.429,RPNAcc=0.989,RPNL1Loss=0.434,RCNNAcc=0.886,RCNNL1Loss=1.725\n",
            "[Epoch 0][Batch 227], Speed: 1.394 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.327,RCNN_SmoothL1=0.428,RPNAcc=0.989,RPNL1Loss=0.433,RCNNAcc=0.886,RCNNL1Loss=1.721\n",
            "[Epoch 0][Batch 228], Speed: 1.304 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.327,RCNN_SmoothL1=0.427,RPNAcc=0.989,RPNL1Loss=0.433,RCNNAcc=0.886,RCNNL1Loss=1.717\n",
            "[Epoch 0][Batch 229], Speed: 1.395 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.326,RCNN_SmoothL1=0.426,RPNAcc=0.989,RPNL1Loss=0.431,RCNNAcc=0.887,RCNNL1Loss=1.713\n",
            "[Epoch 0][Batch 230], Speed: 1.407 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.326,RCNN_SmoothL1=0.425,RPNAcc=0.989,RPNL1Loss=0.431,RCNNAcc=0.887,RCNNL1Loss=1.710\n",
            "[Epoch 0][Batch 231], Speed: 1.202 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.325,RCNN_SmoothL1=0.424,RPNAcc=0.989,RPNL1Loss=0.430,RCNNAcc=0.887,RCNNL1Loss=1.705\n",
            "[Epoch 0][Batch 232], Speed: 1.489 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.325,RCNN_SmoothL1=0.423,RPNAcc=0.989,RPNL1Loss=0.429,RCNNAcc=0.887,RCNNL1Loss=1.701\n",
            "[Epoch 0][Batch 233], Speed: 1.353 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.324,RCNN_SmoothL1=0.422,RPNAcc=0.989,RPNL1Loss=0.428,RCNNAcc=0.887,RCNNL1Loss=1.699\n",
            "[Epoch 0][Batch 234], Speed: 1.399 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.323,RCNN_SmoothL1=0.421,RPNAcc=0.989,RPNL1Loss=0.427,RCNNAcc=0.887,RCNNL1Loss=1.695\n",
            "[Epoch 0][Batch 235], Speed: 1.314 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.323,RCNN_SmoothL1=0.421,RPNAcc=0.989,RPNL1Loss=0.426,RCNNAcc=0.887,RCNNL1Loss=1.692\n",
            "[Epoch 0][Batch 236], Speed: 1.399 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.322,RCNN_SmoothL1=0.420,RPNAcc=0.990,RPNL1Loss=0.426,RCNNAcc=0.887,RCNNL1Loss=1.689\n",
            "[Epoch 0][Batch 237], Speed: 1.350 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.322,RCNN_SmoothL1=0.419,RPNAcc=0.990,RPNL1Loss=0.424,RCNNAcc=0.888,RCNNL1Loss=1.687\n",
            "[Epoch 0][Batch 238], Speed: 1.413 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.321,RCNN_SmoothL1=0.418,RPNAcc=0.990,RPNL1Loss=0.423,RCNNAcc=0.888,RCNNL1Loss=1.683\n",
            "[Epoch 0][Batch 239], Speed: 1.325 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.320,RCNN_SmoothL1=0.417,RPNAcc=0.990,RPNL1Loss=0.422,RCNNAcc=0.888,RCNNL1Loss=1.678\n",
            "[Epoch 0][Batch 240], Speed: 1.381 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.320,RCNN_SmoothL1=0.416,RPNAcc=0.990,RPNL1Loss=0.420,RCNNAcc=0.888,RCNNL1Loss=1.674\n",
            "[Epoch 0][Batch 241], Speed: 1.376 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.319,RCNN_SmoothL1=0.415,RPNAcc=0.990,RPNL1Loss=0.419,RCNNAcc=0.888,RCNNL1Loss=1.670\n",
            "[Epoch 0][Batch 242], Speed: 1.344 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.318,RCNN_SmoothL1=0.414,RPNAcc=0.990,RPNL1Loss=0.418,RCNNAcc=0.889,RCNNL1Loss=1.665\n",
            "[Epoch 0][Batch 243], Speed: 1.337 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.317,RCNN_SmoothL1=0.413,RPNAcc=0.990,RPNL1Loss=0.416,RCNNAcc=0.889,RCNNL1Loss=1.661\n",
            "[Epoch 0][Batch 244], Speed: 1.367 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.317,RCNN_SmoothL1=0.412,RPNAcc=0.990,RPNL1Loss=0.416,RCNNAcc=0.889,RCNNL1Loss=1.658\n",
            "[Epoch 0][Batch 245], Speed: 1.377 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.316,RCNN_SmoothL1=0.411,RPNAcc=0.990,RPNL1Loss=0.415,RCNNAcc=0.889,RCNNL1Loss=1.655\n",
            "[Epoch 0][Batch 246], Speed: 1.370 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.315,RCNN_SmoothL1=0.410,RPNAcc=0.990,RPNL1Loss=0.414,RCNNAcc=0.890,RCNNL1Loss=1.650\n",
            "[Epoch 0][Batch 247], Speed: 1.353 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.315,RCNN_SmoothL1=0.409,RPNAcc=0.990,RPNL1Loss=0.413,RCNNAcc=0.890,RCNNL1Loss=1.647\n",
            "[Epoch 0][Batch 248], Speed: 1.371 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.314,RCNN_SmoothL1=0.409,RPNAcc=0.990,RPNL1Loss=0.412,RCNNAcc=0.890,RCNNL1Loss=1.645\n",
            "[Epoch 0][Batch 249], Speed: 1.322 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.023,RCNN_CrossEntropy=0.313,RCNN_SmoothL1=0.408,RPNAcc=0.990,RPNL1Loss=0.411,RCNNAcc=0.890,RCNNL1Loss=1.642\n",
            "[Epoch 0][Batch 250], Speed: 1.389 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.312,RCNN_SmoothL1=0.407,RPNAcc=0.990,RPNL1Loss=0.410,RCNNAcc=0.891,RCNNL1Loss=1.639\n",
            "[Epoch 0][Batch 251], Speed: 1.376 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.312,RCNN_SmoothL1=0.406,RPNAcc=0.990,RPNL1Loss=0.409,RCNNAcc=0.891,RCNNL1Loss=1.634\n",
            "[Epoch 0][Batch 252], Speed: 1.362 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.311,RCNN_SmoothL1=0.405,RPNAcc=0.990,RPNL1Loss=0.408,RCNNAcc=0.891,RCNNL1Loss=1.630\n",
            "[Epoch 0][Batch 253], Speed: 1.356 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.310,RCNN_SmoothL1=0.404,RPNAcc=0.990,RPNL1Loss=0.407,RCNNAcc=0.892,RCNNL1Loss=1.627\n",
            "[Epoch 0][Batch 254], Speed: 1.352 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.309,RCNN_SmoothL1=0.404,RPNAcc=0.990,RPNL1Loss=0.407,RCNNAcc=0.892,RCNNL1Loss=1.623\n",
            "[Epoch 0][Batch 255], Speed: 1.356 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.309,RCNN_SmoothL1=0.403,RPNAcc=0.990,RPNL1Loss=0.406,RCNNAcc=0.892,RCNNL1Loss=1.620\n",
            "[Epoch 0][Batch 256], Speed: 1.430 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.308,RCNN_SmoothL1=0.402,RPNAcc=0.990,RPNL1Loss=0.406,RCNNAcc=0.892,RCNNL1Loss=1.617\n",
            "[Epoch 0][Batch 257], Speed: 1.350 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.308,RCNN_SmoothL1=0.401,RPNAcc=0.990,RPNL1Loss=0.406,RCNNAcc=0.892,RCNNL1Loss=1.613\n",
            "[Epoch 0][Batch 258], Speed: 1.324 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.307,RCNN_SmoothL1=0.400,RPNAcc=0.990,RPNL1Loss=0.405,RCNNAcc=0.893,RCNNL1Loss=1.609\n",
            "[Epoch 0][Batch 259], Speed: 1.363 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.306,RCNN_SmoothL1=0.399,RPNAcc=0.990,RPNL1Loss=0.405,RCNNAcc=0.893,RCNNL1Loss=1.606\n",
            "[Epoch 0][Batch 260], Speed: 1.375 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.307,RCNN_SmoothL1=0.399,RPNAcc=0.990,RPNL1Loss=0.403,RCNNAcc=0.892,RCNNL1Loss=1.602\n",
            "[Epoch 0][Batch 261], Speed: 1.346 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.307,RCNN_SmoothL1=0.397,RPNAcc=0.990,RPNL1Loss=0.403,RCNNAcc=0.893,RCNNL1Loss=1.598\n",
            "[Epoch 0][Batch 262], Speed: 1.361 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.306,RCNN_SmoothL1=0.396,RPNAcc=0.990,RPNL1Loss=0.402,RCNNAcc=0.893,RCNNL1Loss=1.594\n",
            "[Epoch 0][Batch 263], Speed: 1.372 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.305,RCNN_SmoothL1=0.395,RPNAcc=0.990,RPNL1Loss=0.402,RCNNAcc=0.893,RCNNL1Loss=1.590\n",
            "[Epoch 0][Batch 264], Speed: 1.354 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.304,RCNN_SmoothL1=0.394,RPNAcc=0.990,RPNL1Loss=0.401,RCNNAcc=0.894,RCNNL1Loss=1.586\n",
            "[Epoch 0][Batch 265], Speed: 1.410 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.304,RCNN_SmoothL1=0.393,RPNAcc=0.990,RPNL1Loss=0.401,RCNNAcc=0.894,RCNNL1Loss=1.582\n",
            "[Epoch 0][Batch 266], Speed: 1.367 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.304,RCNN_SmoothL1=0.393,RPNAcc=0.990,RPNL1Loss=0.401,RCNNAcc=0.894,RCNNL1Loss=1.580\n",
            "[Epoch 0][Batch 267], Speed: 1.368 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.304,RCNN_SmoothL1=0.392,RPNAcc=0.990,RPNL1Loss=0.400,RCNNAcc=0.894,RCNNL1Loss=1.577\n",
            "[Epoch 0][Batch 268], Speed: 1.372 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.304,RCNN_SmoothL1=0.391,RPNAcc=0.990,RPNL1Loss=0.400,RCNNAcc=0.894,RCNNL1Loss=1.574\n",
            "[Epoch 0][Batch 269], Speed: 1.410 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.303,RCNN_SmoothL1=0.391,RPNAcc=0.990,RPNL1Loss=0.400,RCNNAcc=0.894,RCNNL1Loss=1.570\n",
            "[Epoch 0][Batch 270], Speed: 1.312 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.303,RCNN_SmoothL1=0.390,RPNAcc=0.990,RPNL1Loss=0.399,RCNNAcc=0.894,RCNNL1Loss=1.569\n",
            "[Epoch 0][Batch 271], Speed: 1.403 samples/sec, RPN_Conf=0.032,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.303,RCNN_SmoothL1=0.389,RPNAcc=0.990,RPNL1Loss=0.399,RCNNAcc=0.894,RCNNL1Loss=1.565\n",
            "[Epoch 0][Batch 272], Speed: 1.362 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.302,RCNN_SmoothL1=0.389,RPNAcc=0.990,RPNL1Loss=0.398,RCNNAcc=0.895,RCNNL1Loss=1.563\n",
            "[Epoch 0][Batch 273], Speed: 1.370 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.302,RCNN_SmoothL1=0.388,RPNAcc=0.990,RPNL1Loss=0.397,RCNNAcc=0.895,RCNNL1Loss=1.559\n",
            "[Epoch 0][Batch 274], Speed: 1.374 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.301,RCNN_SmoothL1=0.387,RPNAcc=0.990,RPNL1Loss=0.396,RCNNAcc=0.895,RCNNL1Loss=1.556\n",
            "[Epoch 0][Batch 275], Speed: 1.363 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.300,RCNN_SmoothL1=0.386,RPNAcc=0.990,RPNL1Loss=0.395,RCNNAcc=0.895,RCNNL1Loss=1.553\n",
            "[Epoch 0][Batch 276], Speed: 1.369 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.301,RCNN_SmoothL1=0.386,RPNAcc=0.990,RPNL1Loss=0.395,RCNNAcc=0.895,RCNNL1Loss=1.552\n",
            "[Epoch 0][Batch 277], Speed: 1.353 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.300,RCNN_SmoothL1=0.385,RPNAcc=0.990,RPNL1Loss=0.395,RCNNAcc=0.895,RCNNL1Loss=1.548\n",
            "[Epoch 0][Batch 278], Speed: 1.313 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.299,RCNN_SmoothL1=0.384,RPNAcc=0.990,RPNL1Loss=0.394,RCNNAcc=0.896,RCNNL1Loss=1.544\n",
            "[Epoch 0][Batch 279], Speed: 1.462 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.299,RCNN_SmoothL1=0.384,RPNAcc=0.990,RPNL1Loss=0.393,RCNNAcc=0.896,RCNNL1Loss=1.542\n",
            "[Epoch 0][Batch 280], Speed: 1.368 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.298,RCNN_SmoothL1=0.383,RPNAcc=0.991,RPNL1Loss=0.392,RCNNAcc=0.896,RCNNL1Loss=1.538\n",
            "[Epoch 0][Batch 281], Speed: 1.382 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.297,RCNN_SmoothL1=0.382,RPNAcc=0.991,RPNL1Loss=0.392,RCNNAcc=0.896,RCNNL1Loss=1.535\n",
            "[Epoch 0][Batch 282], Speed: 1.400 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.297,RCNN_SmoothL1=0.381,RPNAcc=0.991,RPNL1Loss=0.392,RCNNAcc=0.897,RCNNL1Loss=1.532\n",
            "[Epoch 0][Batch 283], Speed: 1.323 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.296,RCNN_SmoothL1=0.380,RPNAcc=0.991,RPNL1Loss=0.392,RCNNAcc=0.897,RCNNL1Loss=1.528\n",
            "[Epoch 0][Batch 284], Speed: 1.522 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.296,RCNN_SmoothL1=0.379,RPNAcc=0.991,RPNL1Loss=0.391,RCNNAcc=0.897,RCNNL1Loss=1.525\n",
            "[Epoch 0][Batch 285], Speed: 1.236 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.022,RCNN_CrossEntropy=0.295,RCNN_SmoothL1=0.378,RPNAcc=0.991,RPNL1Loss=0.390,RCNNAcc=0.897,RCNNL1Loss=1.521\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}